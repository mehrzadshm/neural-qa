{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b16c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/dbpedia/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd596400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'\\nDevice: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7f601",
   "metadata": {},
   "source": [
    "#\n",
    "##  starcoderbase-1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a2ddb33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mehrzad-shahin\r\n"
     ]
    }
   ],
   "source": [
    "## needs HF token with accepted terms of use for this repo\n",
    "# !huggingface-cli logout\n",
    "# !huggingface-cli login\n",
    "!huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fefc4676",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bigcode/starcoderbase-1b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, use_auth_token=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9eab7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBigCodeForCausalLM(\n",
       "  (transformer): GPTBigCodeModel(\n",
       "    (wte): Embedding(49152, 2048)\n",
       "    (wpe): Embedding(8192, 2048)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPTBigCodeBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTBigCodeAttention(\n",
       "          (c_attn): Linear(in_features=2048, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTBigCodeMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): PytorchGELUTanh()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=49152, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4911fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for;\n",
      "# what is the population of Italy?\n",
      "# use following prefixes:\n",
      "\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "\n",
      "SELECT?country?population\n",
      "WHERE {\n",
      "?country dbr:population?population.\n",
      "?country dbo:countryName \"Italy\".\n",
      "}\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"\"\"\n",
    "# write a SPARQL query for;\n",
    "# what is the population of Italy?\n",
    "# use following prefixes:\n",
    "\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93e8a7",
   "metadata": {},
   "source": [
    "#\n",
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ca733eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># write a SPARQL query for:\\n# How many ICD9 d...</td>\n",
       "      <td>select count(*) as ?x where{dbr:Friedreich's_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># write a SPARQL query for:\\n# What was the fa...</td>\n",
       "      <td>select ?x where{dbr:Destrehan_High_School dbo:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># write a SPARQL query for:\\n# Does adventist ...</td>\n",
       "      <td>ask where{dbr:Adventist_Girls_High_School dbo:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># write a SPARQL query for:\\n# Did aliens area...</td>\n",
       "      <td>ask where{dbr:Aliens_Area dbo:lastPublicationD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># write a SPARQL query for:\\n# Did bridget jon...</td>\n",
       "      <td>ask where{dbr:Bridget_Jones:_The_Edge_of_Reaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td># write a SPARQL query for:\\n# What is the pop...</td>\n",
       "      <td>select ?x where{dbr:Southern_Yukaghir_language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td># write a SPARQL query for:\\n# Is washington c...</td>\n",
       "      <td>ask where{dbr:Mitchell_County,_North_Carolina ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td># write a SPARQL query for:\\n# How many marrie...</td>\n",
       "      <td>select count(*) as ?x where{dbr:Bernardine_Doh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td># write a SPARQL query for:\\n# What are the ba...</td>\n",
       "      <td>select ?x where{dbr:Battle_of_Magdala dbo:resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td># write a SPARQL query for:\\n# Did the falu re...</td>\n",
       "      <td>ask where{dbr:Falu_red dbo:rgbCoordinateGreen ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      # write a SPARQL query for:\\n# How many ICD9 d...   \n",
       "1      # write a SPARQL query for:\\n# What was the fa...   \n",
       "2      # write a SPARQL query for:\\n# Does adventist ...   \n",
       "3      # write a SPARQL query for:\\n# Did aliens area...   \n",
       "4      # write a SPARQL query for:\\n# Did bridget jon...   \n",
       "...                                                  ...   \n",
       "99995  # write a SPARQL query for:\\n# What is the pop...   \n",
       "99996  # write a SPARQL query for:\\n# Is washington c...   \n",
       "99997  # write a SPARQL query for:\\n# How many marrie...   \n",
       "99998  # write a SPARQL query for:\\n# What are the ba...   \n",
       "99999  # write a SPARQL query for:\\n# Did the falu re...   \n",
       "\n",
       "                                              completion  \n",
       "0      select count(*) as ?x where{dbr:Friedreich's_a...  \n",
       "1      select ?x where{dbr:Destrehan_High_School dbo:...  \n",
       "2      ask where{dbr:Adventist_Girls_High_School dbo:...  \n",
       "3      ask where{dbr:Aliens_Area dbo:lastPublicationD...  \n",
       "4      ask where{dbr:Bridget_Jones:_The_Edge_of_Reaso...  \n",
       "...                                                  ...  \n",
       "99995  select ?x where{dbr:Southern_Yukaghir_language...  \n",
       "99996  ask where{dbr:Mitchell_County,_North_Carolina ...  \n",
       "99997  select count(*) as ?x where{dbr:Bernardine_Doh...  \n",
       "99998  select ?x where{dbr:Battle_of_Magdala dbo:resu...  \n",
       "99999  ask where{dbr:Falu_red dbo:rgbCoordinateGreen ...  \n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/prompt_tuning_100k.csv\")\n",
    "\n",
    "df = df[['prompt', 'completion']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b845a409",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# How do you calculate 1622 chacornac albedo ?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "SPARQL:\n",
      "select ?x where{dbr:1622_Chacornac dbo:albedo ?x . <B> dbo:albedo ?x }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# What is the minimum elevation of mentonasc dialect's in mentonasc dialect language and reference ?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "SPARQL:\n",
      "select ?x where{dbr:Mentonasc_dialect dbo:spokenIn ?x1 . ?x1 dbo:minimumElevation ?x }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# What does it mean if the frozen of bor lake existed ?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "SPARQL:\n",
      "select ?x where{dbr:Bor_Lake dbo:frozen ?x }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# Where let's switch!'s birthplace was found ?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "SPARQL:\n",
      "select ?x where{dbr:Let's_Switch! dbo:person ?x1 . ?x1 dbo:birthPlace ?x }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# What is the governing body of cakfem-mushere language's spoken in ?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "SPARQL:\n",
      "select ?x where{dbr:Cakfem-Mushere_language dbo:spokenIn ?x1 . ?x1 dbo:governingBody ?x }\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.sample(n=5).iterrows():\n",
    "    print(f\"Prompt:\\n{row['prompt']}\\n\\nSPARQL:\\n{row['completion']}\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80469df3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/mehrzad/.cache/huggingface/datasets/csv/default-5506e1d2153c5efa/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002440929412841797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb2031767d943dd9249c228a1c78d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 70000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['prompt', 'completion'],\n",
      "        num_rows: 30000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "## Load Local CSV Filex to Dataset Format using HugginFace datasets library \n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\n",
    "    'train': '/home/mehrzad/repos/mehrz/dbpedia/data/prompt_tuning/nspm_100k_train.csv', \n",
    "    'test': '/home/mehrzad/repos/mehrz/dbpedia/data/prompt_tuning/nspm_100k_test.csv'\n",
    "})\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33833b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a SPARQL query for:\n",
      "# Did bernard de dryver have any championships ?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "ask where{dbr:Bernard_de_Dryver dbo:championships ?x }\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['prompt'])\n",
    "print(dataset['train'][0]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e8e247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783b3d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28cea31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7570214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, set_peft_model_state_dict\n",
    "from torch.utils.data import IterableDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, logging, set_seed\n",
    "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcd02991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantLengthDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    Iterable dataset that returns constant length chunks of tokens from stream of text files.\n",
    "        Args:\n",
    "            tokenizer (Tokenizer): The processor used for proccessing the data.\n",
    "            dataset (dataset.Dataset): Dataset with text files.\n",
    "            infinite (bool): If True the iterator is reset after dataset reaches end else stops.\n",
    "            seq_length (int): Length of token sequences to return.\n",
    "            num_of_sequences (int): Number of token sequences to keep in buffer.\n",
    "            chars_per_token (int): Number of characters per token used to estimate number of tokens in text buffer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        dataset,\n",
    "        infinite=False,\n",
    "        seq_length=1024,\n",
    "        num_of_sequences=1024,\n",
    "        chars_per_token=3.6,\n",
    "        input_column_name=\"prompt\",\n",
    "        output_column_name=\"completion\"\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.concat_token_id = tokenizer.eos_token_id if tokenizer.eos_token_id is not None else 0\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.infinite = infinite\n",
    "        self.current_size = 0\n",
    "        self.max_buffer_size = seq_length * chars_per_token * num_of_sequences\n",
    "        self.input_column_name = input_column_name\n",
    "        self.output_column_name = output_column_name\n",
    "\n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        more_examples = True\n",
    "        while more_examples:\n",
    "            buffer, buffer_len = [], 0\n",
    "            while True:\n",
    "                if buffer_len >= self.max_buffer_size:\n",
    "                    break\n",
    "                try:\n",
    "                    buffer.append(prepare_sample_text(next(iterator), self.input_column_name, self.output_column_name))\n",
    "                    buffer_len += len(buffer[-1])\n",
    "                except StopIteration:\n",
    "                    if self.infinite:\n",
    "                        iterator = iter(self.dataset)\n",
    "                    else:\n",
    "                        more_examples = False\n",
    "                        break\n",
    "            tokenized_inputs = self.tokenizer(buffer, truncation=False)[\"input_ids\"]\n",
    "            all_token_ids = []\n",
    "            for tokenized_input in tokenized_inputs:\n",
    "                all_token_ids.extend(tokenized_input + [self.concat_token_id])\n",
    "            for i in range(0, len(all_token_ids), self.seq_length):\n",
    "                input_ids = all_token_ids[i : i + self.seq_length]\n",
    "                if len(input_ids) == self.seq_length:\n",
    "                    self.current_size += 1\n",
    "                    yield {\n",
    "                        \"input_ids\": torch.LongTensor(input_ids),\n",
    "                        \"labels\": torch.LongTensor(input_ids),\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "def prepare_sample_text(example, input_column_name=\"prompt\", output_column_name=\"completion\"):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"Question: {example[input_column_name]}\\n\\nAnswer: {example[output_column_name]}\"\n",
    "    return text                    \n",
    "                    \n",
    "\n",
    "    \n",
    "                    \n",
    "def chars_token_ratio(dataset, tokenizer, input_column_name=\"prompt\", output_column_name=\"completion\", nb_examples=400):\n",
    "    \"\"\"\n",
    "    Estimate the average number of characters per token in the dataset.\n",
    "    \"\"\"\n",
    "    total_characters, total_tokens = 0, 0\n",
    "    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n",
    "        text = prepare_sample_text(example, input_column_name, output_column_name)\n",
    "        total_characters += len(text)\n",
    "        if tokenizer.is_fast:\n",
    "            total_tokens += len(tokenizer(text).tokens())\n",
    "        else:\n",
    "            total_tokens += len(tokenizer.tokenize(text))\n",
    "\n",
    "    return total_characters / total_tokens                    \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "                    \n",
    "def create_datasets(tokenizer):\n",
    "    dataset = load_dataset(\n",
    "        'csv', data_files={\n",
    "            'train': '/home/mehrzad/repos/mehrz/dbpedia/data/prompt_tuning/nspm_100k_train.csv',\n",
    "            'test': '/home/mehrzad/repos/mehrz/dbpedia/data/prompt_tuning/nspm_100k_test.csv'\n",
    "}\n",
    "#         args.dataset_name,\n",
    "#         data_dir=args.subset,\n",
    "#         split=args.split,\n",
    "#         use_auth_token=True,\n",
    "#         num_proc=None, ##\n",
    "#         streaming=args.streaming,\n",
    "    )\n",
    "#     if args.streaming:\n",
    "#         print(\"Loading the dataset in streaming mode\")\n",
    "#         valid_data = dataset.take(args.size_valid_set)\n",
    "#         train_data = dataset.skip(args.size_valid_set)\n",
    "#         train_data = train_data.shuffle(buffer_size=args.shuffle_buffer, seed=args.seed)\n",
    "#     else:\n",
    "    train_data = dataset[\"train\"]\n",
    "    valid_data = dataset[\"test\"]\n",
    "    print(f\"Size of the train set: {len(train_data)}. Size of the validation set: {len(valid_data)}\")\n",
    "\n",
    "    chars_per_token = chars_token_ratio(train_data, tokenizer, \"prompt\", \"completion\")\n",
    "    print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n",
    "\n",
    "    train_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        train_data,\n",
    "        infinite=True,\n",
    "        seq_length=2048, ##\n",
    "        chars_per_token=chars_per_token,\n",
    "        input_column_name=\"prompt\", ##\n",
    "        output_column_name=\"completion\" ##\n",
    "    )\n",
    "    valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        valid_data,\n",
    "        infinite=False,\n",
    "        seq_length=2048, ##\n",
    "        chars_per_token=chars_per_token,\n",
    "        input_column_name=\"prompt\", ##\n",
    "        output_column_name=\"completion\" ##\n",
    "    )\n",
    "    return train_dataset, valid_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97fb9bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/mehrzad/.cache/huggingface/datasets/csv/default-5506e1d2153c5efa/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.007750511169433594,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35be0177cc4944f188daa7ded08fc708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train set: 70000. Size of the validation set: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 400/400 [00:00<00:00, 6041.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The character to token ratio of the dataset is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = create_datasets(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182ee185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '# write a SPARQL query for:\\n# What is the power output of a mercedes-benz m117 engine machine ?\\n\\n# use following prefixes:\\nPREFIX dbr: <http://dbpedia.org/resource/>\\nPREFIX dbo: <http://dbpedia.org/ontology/>',\n",
       " 'completion': 'select ?x where{dbr:Mercedes-Benz_M117_engine dbo:powerOutput ?x }'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb3daf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "853f79c8",
   "metadata": {},
   "source": [
    "# \n",
    "## Evaluate fine-tuned model with QALD-9-plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e915867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'question': [{'language': 'en', 'string': 'List all boardgames by GMT.'},\n",
       "  {'language': 'de', 'string': 'Liste die Brettspiele von GMT auf.'},\n",
       "  {'language': 'de', 'string': 'Zeige mir alle Brettspiele von GMT.'},\n",
       "  {'language': 'ru', 'string': 'Перечислите все игры GMT.'},\n",
       "  {'language': 'lt', 'string': 'Išvardinkite visus stalo žaidimus pagal GMT.'},\n",
       "  {'language': 'uk', 'string': 'Перерахуйте всі ігри GMT.'},\n",
       "  {'language': 'lt', 'string': 'Išvardykite visus GMT žaidimus.'},\n",
       "  {'language': 'fr', 'string': 'Listez tous les jeux de société de GMT.'},\n",
       "  {'language': 'es',\n",
       "   'string': '¿Qué juegos de mesa fueron hechos por GMT?',\n",
       "   'keywords': 'juego de mesa ,  GMT '}],\n",
       " 'query': {'sparql': 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> SELECT ?uri WHERE { ?uri dbo:publisher res:GMT_Games }'},\n",
       " 'answers': [{'head': {'link': [], 'vars': ['uri']},\n",
       "   'results': {'bindings': [{'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Chandragupta_(board_game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Fields_of_Fire_(game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Sword_of_Rome'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Paths_of_Glory_(board_game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Commands_&_Colors:_Ancients'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Labyrinth:_The_War_on_Terror,_2001_–_%3F'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Twilight_Struggle'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': \"http://dbpedia.org/resource/Washington's_War\"}}]}}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('data/qald_9_plus_train_dbpedia.json', 'r') as f:\n",
    "    qald_9_plus_data = json.load(f)\n",
    "    \n",
    "qald_9_plus_data['questions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434c25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 pairs extracted from train set:  \n",
      "\n",
      "List all boardgames by GMT.\n",
      "\n",
      " PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      " PREFIX res: <http://dbpedia.org/resource/>\n",
      " PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      " SELECT ?uri WHERE { ?uri dbo:publisher res:GMT_Games }\n"
     ]
    }
   ],
   "source": [
    "# extracting pairs of question/sparql    \n",
    "    \n",
    "nl_questions, sparql_queries =[],[]\n",
    "\n",
    "for data in qald_9_plus_data['questions']:\n",
    "    nl_questions.append(\n",
    "        next((item['string'] for item in data['question'] if item['language'] == 'en'), None)\n",
    "    )\n",
    "    sparql_queries.append(data['query']['sparql'])\n",
    "    \n",
    "\n",
    "print(f'{len(nl_questions)} pairs extracted from train set: ', \"\\n\")\n",
    "print(nl_questions[0])\n",
    "print('\\n', sparql_queries[0].replace(\">\", '>\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84d503",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "### Calculate BELUE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e301444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO \n",
    "# debug the script  \n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "def read_dataset(path):\n",
    "    dataset = pd.read_csv(path)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def generate_sparql(model, tokenizer, question):\n",
    "    inputs = tokenizer.encode(question, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(inputs, max_length=100, num_beams=5, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0])\n",
    "\n",
    "\n",
    "def calculate_bleu(actual, generated):\n",
    "    bleu_metric = load_metric('bleu')\n",
    "    bleu_score = bleu_metric.compute(predictions=[generated.split()], references=[[actual.split()]])\n",
    "    return bleu_score['bleu']\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    models = [\n",
    "#         \"Salesforce/codegen-350M-multi\", \"Salesforce/codegen25-7b-instruct\", \n",
    "#         \"bigcode/starcoderbase-3b\", \"bigcode/starcoderbase-1b\",\n",
    "#         \"EleutherAI/gpt-neo-2.7B\", \"tiiuae/falcon-rw-1b\"\n",
    "              \n",
    "            ]  \n",
    "\n",
    "    # TODO\n",
    "    dataset_path = \"/home/mehrzad/repos/mehrz/dbpedia/data/prompt_tuning/qald-9-plus.csv\"\n",
    "\n",
    "    dataset = read_dataset(dataset_path)\n",
    "\n",
    "    for model_name in models:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "        \n",
    "        device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        model.to(device)\n",
    "\n",
    "        results = []\n",
    "        total_bleu_score = 0\n",
    "\n",
    "        for idx, row in dataset.iterrows():\n",
    "            question, actual_sparql = row['question'], row['sparql_query']\n",
    "            generated_sparql = generate_sparql(model, tokenizer, question)\n",
    "\n",
    "            bleu_score = calculate_bleu(actual_sparql, generated_sparql)\n",
    "\n",
    "            results.append((question, actual_sparql, generated_sparql, bleu_score))\n",
    "\n",
    "            total_bleu_score += bleu_score\n",
    "\n",
    "        average_bleu_score = total_bleu_score / len(dataset)\n",
    "\n",
    "        print(f\"Results for {model_name}:\\n\", results)\n",
    "        print(f\"Average BLEU score for {model_name}: \", average_bleu_score)\n",
    "        \n",
    "        \n",
    "        # delete the model and tokenizer to free up memory\n",
    "        del model\n",
    "        del tokenizer\n",
    "\n",
    "        # clear the GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbpedia-env",
   "language": "python",
   "name": "dbpedia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
