{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b16c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehrzad/anaconda3/envs/dbpedia/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd596400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'\\nDevice: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7f601",
   "metadata": {},
   "source": [
    "#\n",
    "##  starcoderbase-1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2ddb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## needs HF token with accepted terms of use for this repo\n",
    "# !huggingface-cli logout\n",
    "# !huggingface-cli login\n",
    "# !huggingface-cli whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c9f860d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenizer.json',\n",
       " 'generation_config.json',\n",
       " 'tokenizer_config.json',\n",
       " 'model.safetensors',\n",
       " 'merges.txt',\n",
       " 'config.json',\n",
       " 'vocab.json',\n",
       " 'special_tokens_map.json']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"/home/mehrzad/.cache/huggingface/hub/models--bigcode--starcoderbase-1b/snapshots/109288100c382424b748a488287e4ef7cd7007b3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fefc4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint = \"bigcode/starcoderbase-1b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, use_auth_token=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9eab7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTBigCodeForCausalLM(\n",
       "  (transformer): GPTBigCodeModel(\n",
       "    (wte): Embedding(49152, 2048)\n",
       "    (wpe): Embedding(8192, 2048)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPTBigCodeBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTBigCodeAttention(\n",
       "          (c_attn): Linear(in_features=2048, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTBigCodeMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): PytorchGELUTanh()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=49152, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4911fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for;\n",
      "# what is the population of Italy?\n",
      "# use following prefixes:\n",
      "\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "\n",
      "SELECT?country?population\n",
      "WHERE {\n",
      "?country dbr:population?population.\n",
      "?country dbo:countryName \"Italy\".\n",
      "}\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"\"\"\n",
    "# write a SPARQL query for;\n",
    "# what is the population of Italy?\n",
    "# use following prefixes:\n",
    "\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "111def1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for:\n",
      "# What was the population of Italy in year 2000?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
      "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "PREFIX owl: <http://www.w3.org/2002/07\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"\"\"\n",
    "# write a SPARQL query for:\n",
    "# What was the population of Italy in year 2000 ?\n",
    "\n",
    "# use following prefixes:\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de93e8a7",
   "metadata": {},
   "source": [
    "#\n",
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ca733eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3382376</td>\n",
       "      <td># write a SPARQL query for:\\n# How many ICD9 d...</td>\n",
       "      <td>select count(*) as ?x where{dbr:Friedreich's_a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2559914</td>\n",
       "      <td># write a SPARQL query for:\\n# What was the fa...</td>\n",
       "      <td>select ?x where{dbr:Destrehan_High_School dbo:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2990831</td>\n",
       "      <td># write a SPARQL query for:\\n# Does adventist ...</td>\n",
       "      <td>ask where{dbr:Adventist_Girls_High_School dbo:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1637967</td>\n",
       "      <td># write a SPARQL query for:\\n# Did aliens area...</td>\n",
       "      <td>ask where{dbr:Aliens_Area dbo:lastPublicationD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1507546</td>\n",
       "      <td># write a SPARQL query for:\\n# Did bridget jon...</td>\n",
       "      <td>ask where{dbr:Bridget_Jones:_The_Edge_of_Reaso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>7260453</td>\n",
       "      <td># write a SPARQL query for:\\n# What is the pop...</td>\n",
       "      <td>select ?x where{dbr:Southern_Yukaghir_language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>6784536</td>\n",
       "      <td># write a SPARQL query for:\\n# Is washington c...</td>\n",
       "      <td>ask where{dbr:Mitchell_County,_North_Carolina ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>3733762</td>\n",
       "      <td># write a SPARQL query for:\\n# How many marrie...</td>\n",
       "      <td>select count(*) as ?x where{dbr:Bernardine_Doh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>7637742</td>\n",
       "      <td># write a SPARQL query for:\\n# What are the ba...</td>\n",
       "      <td>select ?x where{dbr:Battle_of_Magdala dbo:resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>5249851</td>\n",
       "      <td># write a SPARQL query for:\\n# Did the falu re...</td>\n",
       "      <td>ask where{dbr:Falu_red dbo:rgbCoordinateGreen ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                             prompt  \\\n",
       "0         3382376  # write a SPARQL query for:\\n# How many ICD9 d...   \n",
       "1         2559914  # write a SPARQL query for:\\n# What was the fa...   \n",
       "2         2990831  # write a SPARQL query for:\\n# Does adventist ...   \n",
       "3         1637967  # write a SPARQL query for:\\n# Did aliens area...   \n",
       "4         1507546  # write a SPARQL query for:\\n# Did bridget jon...   \n",
       "...           ...                                                ...   \n",
       "99995     7260453  # write a SPARQL query for:\\n# What is the pop...   \n",
       "99996     6784536  # write a SPARQL query for:\\n# Is washington c...   \n",
       "99997     3733762  # write a SPARQL query for:\\n# How many marrie...   \n",
       "99998     7637742  # write a SPARQL query for:\\n# What are the ba...   \n",
       "99999     5249851  # write a SPARQL query for:\\n# Did the falu re...   \n",
       "\n",
       "                                              completion  \n",
       "0      select count(*) as ?x where{dbr:Friedreich's_a...  \n",
       "1      select ?x where{dbr:Destrehan_High_School dbo:...  \n",
       "2      ask where{dbr:Adventist_Girls_High_School dbo:...  \n",
       "3      ask where{dbr:Aliens_Area dbo:lastPublicationD...  \n",
       "4      ask where{dbr:Bridget_Jones:_The_Edge_of_Reaso...  \n",
       "...                                                  ...  \n",
       "99995  select ?x where{dbr:Southern_Yukaghir_language...  \n",
       "99996  ask where{dbr:Mitchell_County,_North_Carolina ...  \n",
       "99997  select count(*) as ?x where{dbr:Bernardine_Doh...  \n",
       "99998  select ?x where{dbr:Battle_of_Magdala dbo:resu...  \n",
       "99999  ask where{dbr:Falu_red dbo:rgbCoordinateGreen ...  \n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/nspm-fine-tuning/train.csv\")\n",
    "\n",
    "# df = df[['prompt', 'completion']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b845a409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# How many leaderFunction did deutsche sammlung von mikroorganismen und zellkulturen have ?\n",
      "\n",
      "SPARQL:\n",
      "select count(*) as ?x where{dbr:Deutsche_Sammlung_von_Mikroorganismen_und_Zellkulturen dbo:leaderFunction ?x }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# Who is tuesday's guest's subsidiary ?\n",
      "\n",
      "SPARQL:\n",
      "select ?x where{dbr:Tuesday's_Guest dbo:productionCompany ?x1 . ?x1 dbo:subsidiary ?x }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# How many fuel systems did ferrari v8 f1 engine have ?\n",
      "\n",
      "SPARQL:\n",
      "select count(*) as ?x where{dbr:Ferrari_V8_F1_engine dbo:fuelSystem ?x }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# Did superior vesical artery branch come from ileal arteries ?\n",
      "\n",
      "SPARQL:\n",
      "ask where{dbr:Ileal_arteries dbo:branchFrom dbr:Superior_vesical_artery }\n",
      "================================================================================\n",
      "Prompt:\n",
      "# write a SPARQL query for:\n",
      "# What colour used in school gann academy ?\n",
      "\n",
      "SPARQL:\n",
      "select ?x where{dbr:Gann_Academy dbo:officialSchoolColour ?x }\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.sample(n=5).iterrows():\n",
    "    print(f\"Prompt:\\n{row['prompt']}\\n\\nSPARQL:\\n{row['completion']}\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80469df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/mehrzad/.cache/huggingface/datasets/csv/default-a3e3d434e059fc25/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003603219985961914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Downloading data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1074624ec9440448719b6fe16e3d800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006365537643432617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Extracting data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a4a07abc194ac4be977c868eb944f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00583338737487793,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Generating train split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a1c909a7414cb5b977c9a2ee3eb84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0024378299713134766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "Generating val split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bb8f4b002b4ec2a0339b36ffc9a489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/mehrzad/.cache/huggingface/datasets/csv/default-a3e3d434e059fc25/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002500295639038086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 22,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233bf6e1ce8d47bda4e10499a980f243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'prompt', 'completion'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['Unnamed: 0', 'prompt', 'completion'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "## Load Local CSV Filex to Dataset Format using HugginFace datasets library \n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\n",
    "    'train': '/home/mehrzad/repos/mehrz/dbpedia/data/nspm-fine-tuning/train.csv', \n",
    "    'val': '/home/mehrzad/repos/mehrz/dbpedia/data/nspm-fine-tuning/val.csv'\n",
    "})\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33833b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a SPARQL query for:\n",
      "# How many ICD9 did friedreich's ataxia have ?\n",
      "select count(*) as ?x where{dbr:Friedreich's_ataxia dbo:icd9 ?x }\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['prompt'])\n",
    "print(dataset['train'][0]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfde84a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a SPARQL query for:\n",
      "# Did 1946 vancouver island earthquake lose any of its comrades ?\n",
      "ask where{dbr:1946_Vancouver_Island_earthquake dbo:casualties ?x }\n"
     ]
    }
   ],
   "source": [
    "print(dataset['val'][0]['prompt'])\n",
    "print(dataset['val'][0]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7570214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, set_peft_model_state_dict\n",
    "from torch.utils.data import IterableDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, logging, set_seed\n",
    "from transformers import TrainerCallback, TrainingArguments, TrainerState, TrainerControl\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcd02991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantLengthDataset(IterableDataset):\n",
    "    \"\"\"\n",
    "    Iterable dataset that returns constant length chunks of tokens from stream of text files.\n",
    "        Args:\n",
    "            tokenizer (Tokenizer): The processor used for proccessing the data.\n",
    "            dataset (dataset.Dataset): Dataset with text files.\n",
    "            infinite (bool): If True the iterator is reset after dataset reaches end else stops.\n",
    "            seq_length (int): Length of token sequences to return.\n",
    "            num_of_sequences (int): Number of token sequences to keep in buffer.\n",
    "            chars_per_token (int): Number of characters per token used to estimate number of tokens in text buffer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        dataset,\n",
    "        infinite=False,\n",
    "        seq_length=1024,\n",
    "        num_of_sequences=1024,\n",
    "        chars_per_token=3.6,\n",
    "        input_column_name=\"prompt\",\n",
    "        output_column_name=\"completion\"\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.concat_token_id = tokenizer.eos_token_id if tokenizer.eos_token_id is not None else 0\n",
    "        self.dataset = dataset\n",
    "        self.seq_length = seq_length\n",
    "        self.infinite = infinite\n",
    "        self.current_size = 0\n",
    "        self.max_buffer_size = seq_length * chars_per_token * num_of_sequences\n",
    "        self.input_column_name = input_column_name\n",
    "        self.output_column_name = output_column_name\n",
    "\n",
    "    def __iter__(self):\n",
    "        iterator = iter(self.dataset)\n",
    "        more_examples = True\n",
    "        while more_examples:\n",
    "            buffer, buffer_len = [], 0\n",
    "            while True:\n",
    "                if buffer_len >= self.max_buffer_size:\n",
    "                    break\n",
    "                try:\n",
    "                    buffer.append(prepare_sample_text(next(iterator), self.input_column_name, self.output_column_name))\n",
    "                    buffer_len += len(buffer[-1])\n",
    "                except StopIteration:\n",
    "                    if self.infinite:\n",
    "                        iterator = iter(self.dataset)\n",
    "                    else:\n",
    "                        more_examples = False\n",
    "                        break\n",
    "            tokenized_inputs = self.tokenizer(buffer, truncation=False)[\"input_ids\"]\n",
    "            all_token_ids = []\n",
    "            for tokenized_input in tokenized_inputs:\n",
    "                all_token_ids.extend(tokenized_input + [self.concat_token_id])\n",
    "            for i in range(0, len(all_token_ids), self.seq_length):\n",
    "                input_ids = all_token_ids[i : i + self.seq_length]\n",
    "                if len(input_ids) == self.seq_length:\n",
    "                    self.current_size += 1\n",
    "                    yield {\n",
    "                        \"input_ids\": torch.LongTensor(input_ids),\n",
    "                        \"labels\": torch.LongTensor(input_ids),\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "                    \n",
    "def prepare_sample_text(example, input_column_name=\"prompt\", output_column_name=\"completion\"):\n",
    "    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n",
    "    text = f\"Question: {example[input_column_name]}\\n\\nAnswer: {example[output_column_name]}\"\n",
    "    return text                    \n",
    "                    \n",
    "\n",
    "    \n",
    "                    \n",
    "def chars_token_ratio(dataset, tokenizer, input_column_name=\"prompt\", output_column_name=\"completion\", nb_examples=400):\n",
    "    \"\"\"\n",
    "    Estimate the average number of characters per token in the dataset.\n",
    "    \"\"\"\n",
    "    total_characters, total_tokens = 0, 0\n",
    "    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n",
    "        text = prepare_sample_text(example, input_column_name, output_column_name)\n",
    "        total_characters += len(text)\n",
    "        if tokenizer.is_fast:\n",
    "            total_tokens += len(tokenizer(text).tokens())\n",
    "        else:\n",
    "            total_tokens += len(tokenizer.tokenize(text))\n",
    "\n",
    "    return total_characters / total_tokens                    \n",
    " \n",
    "    \n",
    "    \n",
    "                    \n",
    "def create_datasets(tokenizer):\n",
    "    dataset = load_dataset(\n",
    "        'csv', data_files={\n",
    "            'train': 'data/nspm_100k_train.csv',\n",
    "            'test': 'data/nspm_100k_test.csv'\n",
    "}\n",
    "#         args.dataset_name,\n",
    "#         data_dir=args.subset,\n",
    "#         split=args.split,\n",
    "#         use_auth_token=True,\n",
    "#         num_proc=None, ##\n",
    "#         streaming=args.streaming,\n",
    "    )\n",
    "#     if args.streaming:\n",
    "#         print(\"Loading the dataset in streaming mode\")\n",
    "#         valid_data = dataset.take(args.size_valid_set)\n",
    "#         train_data = dataset.skip(args.size_valid_set)\n",
    "#         train_data = train_data.shuffle(buffer_size=args.shuffle_buffer, seed=args.seed)\n",
    "#     else:\n",
    "    train_data = dataset[\"train\"]\n",
    "    valid_data = dataset[\"test\"]\n",
    "    print(f\"Size of the train set: {len(train_data)}. Size of the validation set: {len(valid_data)}\")\n",
    "\n",
    "    chars_per_token = chars_token_ratio(train_data, tokenizer, \"prompt\", \"completion\")\n",
    "    print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n",
    "\n",
    "    train_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        train_data,\n",
    "        infinite=True,\n",
    "        seq_length=2048, ##\n",
    "        chars_per_token=chars_per_token,\n",
    "        input_column_name=\"prompt\", ##\n",
    "        output_column_name=\"completion\" ##\n",
    "    )\n",
    "    valid_dataset = ConstantLengthDataset(\n",
    "        tokenizer,\n",
    "        valid_data,\n",
    "        infinite=False,\n",
    "        seq_length=2048, ##\n",
    "        chars_per_token=chars_per_token,\n",
    "        input_column_name=\"prompt\", ##\n",
    "        output_column_name=\"completion\" ##\n",
    "    )\n",
    "    return train_dataset, valid_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97fb9bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/mehrzad/.cache/huggingface/datasets/csv/default-2ecec2e06c3917ec/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0070629119873046875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Downloading data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71417c335d57430e9275f466f625de9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003381490707397461,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Extracting data files",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb99ba699f4f4bfba524490e95549a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004108905792236328,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Generating train split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228abc05d52f48fd9e5ed6c87f2011f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00252532958984375,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "Generating test split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1549977d25488db67508b9a82f8119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/mehrzad/.cache/huggingface/datasets/csv/default-2ecec2e06c3917ec/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002370119094848633,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96db1459f23448d5b26472851ec4d76b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train set: 70000. Size of the validation set: 30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 400/400 [00:00<00:00, 6637.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The character to token ratio of the dataset is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset = create_datasets(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "182ee185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': '# write a SPARQL query for:\\n# What is the power output of a mercedes-benz m117 engine machine ?\\n\\n# use following prefixes:\\nPREFIX dbr: <http://dbpedia.org/resource/>\\nPREFIX dbo: <http://dbpedia.org/ontology/>',\n",
       " 'completion': 'select ?x where{dbr:Mercedes-Benz_M117_engine dbo:powerOutput ?x }'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394553c",
   "metadata": {},
   "source": [
    "#\n",
    "## Training for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97ce1c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/mehrzad/anaconda3/envs/tf-2.9/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Found cached dataset csv (/home/mehrzad/.cache/huggingface/datasets/csv/default-2ecec2e06c3917ec/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1116.25it/s]\n",
      "Size of the train set: 70000. Size of the validation set: 30000\n",
      "100%|███████████████████████████████████████| 400/400 [00:00<00:00, 6106.67it/s]\n",
      "The character to token ratio of the dataset is: 2.98\n",
      "Loading the model\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "trainable params: 7176192 || all params: 1144383488 || trainable%: 0.6270793029827428\n",
      "Starting main loop\n",
      "Training...\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 1.3077, 'learning_rate': 5e-06, 'epoch': 0.01}\n",
      "{'eval_loss': 1.1688510179519653, 'eval_runtime': 677.2213, 'eval_samples_per_second': 2.172, 'eval_steps_per_second': 2.172, 'epoch': 0.01}\n",
      "{'loss': 1.0817, 'learning_rate': 4.998741355957963e-06, 'epoch': 0.02}\n",
      "{'eval_loss': 0.9329292178153992, 'eval_runtime': 740.1093, 'eval_samples_per_second': 1.988, 'eval_steps_per_second': 1.988, 'epoch': 0.02}\n",
      "{'loss': 0.9201, 'learning_rate': 4.994966691179712e-06, 'epoch': 0.03}\n",
      "{'eval_loss': 0.8598676919937134, 'eval_runtime': 739.5135, 'eval_samples_per_second': 1.989, 'eval_steps_per_second': 1.989, 'epoch': 0.03}\n",
      "{'loss': 0.8631, 'learning_rate': 4.988679806432712e-06, 'epoch': 0.04}\n",
      "{'eval_loss': 0.8117868304252625, 'eval_runtime': 712.6062, 'eval_samples_per_second': 2.064, 'eval_steps_per_second': 2.064, 'epoch': 0.04}\n",
      "{'loss': 0.823, 'learning_rate': 4.9798870320769884e-06, 'epoch': 0.05}\n",
      "{'eval_loss': 0.7829549908638, 'eval_runtime': 723.451, 'eval_samples_per_second': 2.033, 'eval_steps_per_second': 2.033, 'epoch': 0.05}\n",
      "{'loss': 0.8008, 'learning_rate': 4.968597221690986e-06, 'epoch': 0.06}\n",
      "{'eval_loss': 0.7647002339363098, 'eval_runtime': 674.36, 'eval_samples_per_second': 2.181, 'eval_steps_per_second': 2.181, 'epoch': 0.06}\n",
      "{'loss': 0.7838, 'learning_rate': 4.9548217431567665e-06, 'epoch': 0.07}\n",
      "{'eval_loss': 0.7523472905158997, 'eval_runtime': 674.0422, 'eval_samples_per_second': 2.182, 'eval_steps_per_second': 2.182, 'epoch': 0.07}\n",
      "{'loss': 0.7733, 'learning_rate': 4.938574467213519e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 0.7431109547615051, 'eval_runtime': 673.4572, 'eval_samples_per_second': 2.184, 'eval_steps_per_second': 2.184, 'epoch': 0.08}\n",
      "{'loss': 0.7615, 'learning_rate': 4.919871753490892e-06, 'epoch': 0.09}\n",
      "{'eval_loss': 0.7354047298431396, 'eval_runtime': 672.987, 'eval_samples_per_second': 2.186, 'eval_steps_per_second': 2.186, 'epoch': 0.09}\n",
      "{'loss': 0.7561, 'learning_rate': 4.8987324340362445e-06, 'epoch': 0.1}\n",
      "{'eval_loss': 0.7289052605628967, 'eval_runtime': 673.6346, 'eval_samples_per_second': 2.184, 'eval_steps_per_second': 2.184, 'epoch': 0.1}\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.7494, 'learning_rate': 4.875177794352364e-06, 'epoch': 0.11}\n",
      "{'eval_loss': 0.7230220437049866, 'eval_runtime': 672.8871, 'eval_samples_per_second': 2.186, 'eval_steps_per_second': 2.186, 'epoch': 0.11}\n",
      "{'loss': 0.742, 'learning_rate': 4.849231551964771e-06, 'epoch': 0.12}\n",
      "{'eval_loss': 0.718217670917511, 'eval_runtime': 674.6151, 'eval_samples_per_second': 2.181, 'eval_steps_per_second': 2.181, 'epoch': 0.12}\n",
      "{'loss': 0.7395, 'learning_rate': 4.8209198325401815e-06, 'epoch': 0.13}\n",
      "{'eval_loss': 0.7134671211242676, 'eval_runtime': 673.7699, 'eval_samples_per_second': 2.183, 'eval_steps_per_second': 2.183, 'epoch': 0.13}\n",
      "{'loss': 0.7329, 'learning_rate': 4.790271143580174e-06, 'epoch': 0.14}\n",
      "{'eval_loss': 0.7091519236564636, 'eval_runtime': 672.9621, 'eval_samples_per_second': 2.186, 'eval_steps_per_second': 2.186, 'epoch': 0.14}\n",
      "{'loss': 0.7299, 'learning_rate': 4.757316345716554e-06, 'epoch': 0.15}\n",
      "{'eval_loss': 0.7052786350250244, 'eval_runtime': 673.0659, 'eval_samples_per_second': 2.186, 'eval_steps_per_second': 2.186, 'epoch': 0.15}\n",
      "{'loss': 0.7254, 'learning_rate': 4.7220886216373095e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 0.7016641497612, 'eval_runtime': 676.2062, 'eval_samples_per_second': 2.175, 'eval_steps_per_second': 2.175, 'epoch': 0.16}\n",
      "{'loss': 0.7228, 'learning_rate': 4.684623442674463e-06, 'epoch': 0.17}\n",
      "{'eval_loss': 0.6983733177185059, 'eval_runtime': 672.758, 'eval_samples_per_second': 2.187, 'eval_steps_per_second': 2.187, 'epoch': 0.17}\n",
      "{'loss': 0.7181, 'learning_rate': 4.644958533087443e-06, 'epoch': 0.18}\n",
      "{'eval_loss': 0.6951935291290283, 'eval_runtime': 716.9757, 'eval_samples_per_second': 2.052, 'eval_steps_per_second': 2.052, 'epoch': 0.18}\n",
      "{'loss': 0.7162, 'learning_rate': 4.603133832077953e-06, 'epoch': 0.19}\n",
      "{'eval_loss': 0.6923752427101135, 'eval_runtime': 672.5331, 'eval_samples_per_second': 2.187, 'eval_steps_per_second': 2.187, 'epoch': 0.19}\n",
      "{'loss': 0.7117, 'learning_rate': 4.559191453574582e-06, 'epoch': 0.2}\n",
      "{'eval_loss': 0.6893517374992371, 'eval_runtime': 702.9905, 'eval_samples_per_second': 2.092, 'eval_steps_per_second': 2.092, 'epoch': 0.2}\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "^C\n",
      "CPU times: user 6min 40s, sys: 1min 30s, total: 8min 10s\n",
      "Wall time: 23h 37min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python finetune-starcoder-1b.py\\\n",
    "--model_path=\"bigcode/starcoderbase-1b\"\\\n",
    "--eos_token_id=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2500f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to bigcode/starcoderbase-1b-merged\r\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python merge_peft_adapters.py\\\n",
    "--base_model_name_or_path=\"bigcode/starcoderbase-1b\"\\\n",
    "--peft_model_path=\"./checkpoints/checkpoint-2000/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c37490a-8fdc-484f-ad6c-97e0ec0aa070",
   "metadata": {},
   "source": [
    "## 2nd round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56fc3b04-521c-43bf-9aaf-a86e708b11b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90c9f0a-8ed7-4ff2-b779-b00db5d02050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Using CUDA device: NVIDIA GeForce RTX 3090\n",
      "Memory Allocated: 0.00 MB\n",
      "Memory Reserved: 0.00 MB\n",
      "\n",
      "\n",
      "\n",
      "Found cached dataset csv (/home/mehr-shahin/.cache/huggingface/datasets/csv/default-3615beb83b6f428b/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "100%|███████████████████████████████████████████| 2/2 [00:00<00:00, 1019.77it/s]\n",
      "Size of the train set: 100000. Size of the validation set: 20000\n",
      "100%|███████████████████████████████████████| 400/400 [00:00<00:00, 6434.24it/s]\n",
      "The character to token ratio of the dataset is: 2.89\n",
      "Loading the model\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "trainable params: 7176192 || all params: 1144383488 || trainable%: 0.6270793029827428\n",
      "Starting main loop\n",
      "Training...\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 1.9037, 'learning_rate': 5e-06, 'epoch': 0.01}\n",
      "{'eval_loss': 1.6952102184295654, 'eval_runtime': 123.7314, 'eval_samples_per_second': 5.076, 'eval_steps_per_second': 1.269, 'epoch': 0.01}\n",
      "{'loss': 1.5517, 'learning_rate': 4.998741355957963e-06, 'epoch': 0.02}\n",
      "{'eval_loss': 1.343339443206787, 'eval_runtime': 125.4568, 'eval_samples_per_second': 5.006, 'eval_steps_per_second': 1.251, 'epoch': 0.02}\n",
      "{'loss': 1.3434, 'learning_rate': 4.994966691179712e-06, 'epoch': 0.03}\n",
      "{'eval_loss': 1.268519639968872, 'eval_runtime': 123.8344, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 1.268, 'epoch': 0.03}\n",
      "{'loss': 1.2831, 'learning_rate': 4.988679806432712e-06, 'epoch': 0.04}\n",
      "{'eval_loss': 1.2175984382629395, 'eval_runtime': 123.8565, 'eval_samples_per_second': 5.07, 'eval_steps_per_second': 1.268, 'epoch': 0.04}\n",
      "{'loss': 1.2374, 'learning_rate': 4.9798870320769884e-06, 'epoch': 0.05}\n",
      "{'eval_loss': 1.1772842407226562, 'eval_runtime': 123.9403, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.05}\n",
      "{'loss': 1.203, 'learning_rate': 4.968597221690986e-06, 'epoch': 0.06}\n",
      "{'eval_loss': 1.1507834196090698, 'eval_runtime': 123.7958, 'eval_samples_per_second': 5.073, 'eval_steps_per_second': 1.268, 'epoch': 0.06}\n",
      "{'loss': 1.1797, 'learning_rate': 4.9548217431567665e-06, 'epoch': 0.07}\n",
      "{'eval_loss': 1.1316007375717163, 'eval_runtime': 123.7921, 'eval_samples_per_second': 5.073, 'eval_steps_per_second': 1.268, 'epoch': 0.07}\n",
      "{'loss': 1.1619, 'learning_rate': 4.938574467213519e-06, 'epoch': 0.08}\n",
      "{'eval_loss': 1.1163883209228516, 'eval_runtime': 123.9815, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.266, 'epoch': 0.08}\n",
      "{'loss': 1.1476, 'learning_rate': 4.919871753490892e-06, 'epoch': 0.09}\n",
      "{'eval_loss': 1.1035336256027222, 'eval_runtime': 123.8423, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 1.268, 'epoch': 0.09}\n",
      "{'loss': 1.1351, 'learning_rate': 4.8987324340362445e-06, 'epoch': 0.1}\n",
      "{'eval_loss': 1.0926017761230469, 'eval_runtime': 123.7639, 'eval_samples_per_second': 5.074, 'eval_steps_per_second': 1.269, 'epoch': 0.1}\n",
      "{'loss': 1.1243, 'learning_rate': 4.875177794352364e-06, 'epoch': 0.11}\n",
      "{'eval_loss': 1.082777976989746, 'eval_runtime': 123.7384, 'eval_samples_per_second': 5.075, 'eval_steps_per_second': 1.269, 'epoch': 0.11}\n",
      "{'loss': 1.1154, 'learning_rate': 4.849231551964771e-06, 'epoch': 0.12}\n",
      "{'eval_loss': 1.0739022493362427, 'eval_runtime': 123.9817, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.266, 'epoch': 0.12}\n",
      "{'loss': 1.1066, 'learning_rate': 4.8209198325401815e-06, 'epoch': 0.13}\n",
      "{'eval_loss': 1.0659602880477905, 'eval_runtime': 123.6104, 'eval_samples_per_second': 5.08, 'eval_steps_per_second': 1.27, 'epoch': 0.13}\n",
      "{'loss': 1.099, 'learning_rate': 4.790271143580174e-06, 'epoch': 0.14}\n",
      "{'eval_loss': 1.0586369037628174, 'eval_runtime': 123.723, 'eval_samples_per_second': 5.076, 'eval_steps_per_second': 1.269, 'epoch': 0.14}\n",
      "{'loss': 1.0922, 'learning_rate': 4.757316345716554e-06, 'epoch': 0.15}\n",
      "{'eval_loss': 1.0518893003463745, 'eval_runtime': 123.8455, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 1.268, 'epoch': 0.15}\n",
      "{'loss': 1.0854, 'learning_rate': 4.7220886216373095e-06, 'epoch': 0.16}\n",
      "{'eval_loss': 1.045580267906189, 'eval_runtime': 123.8854, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 1.267, 'epoch': 0.16}\n",
      "{'loss': 1.0793, 'learning_rate': 4.684623442674463e-06, 'epoch': 0.17}\n",
      "{'eval_loss': 1.039792537689209, 'eval_runtime': 123.8941, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 1.267, 'epoch': 0.17}\n",
      "{'loss': 1.0738, 'learning_rate': 4.644958533087443e-06, 'epoch': 0.18}\n",
      "{'eval_loss': 1.0340900421142578, 'eval_runtime': 123.9312, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.18}\n",
      "{'loss': 1.0681, 'learning_rate': 4.603133832077953e-06, 'epoch': 0.19}\n",
      "{'eval_loss': 1.0286668539047241, 'eval_runtime': 123.9582, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.267, 'epoch': 0.19}\n",
      "{'loss': 1.0631, 'learning_rate': 4.559191453574582e-06, 'epoch': 0.2}\n",
      "{'eval_loss': 1.0235998630523682, 'eval_runtime': 123.7359, 'eval_samples_per_second': 5.075, 'eval_steps_per_second': 1.269, 'epoch': 0.2}\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 1.058, 'learning_rate': 4.513175643827647e-06, 'epoch': 0.21}\n",
      "{'eval_loss': 1.0188361406326294, 'eval_runtime': 123.7276, 'eval_samples_per_second': 5.076, 'eval_steps_per_second': 1.269, 'epoch': 0.21}\n",
      "{'loss': 1.0535, 'learning_rate': 4.4651327368569695e-06, 'epoch': 0.22}\n",
      "{'eval_loss': 1.0142651796340942, 'eval_runtime': 123.9449, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.22}\n",
      "{'loss': 1.0491, 'learning_rate': 4.415111107797445e-06, 'epoch': 0.23}\n",
      "{'eval_loss': 1.0097774267196655, 'eval_runtime': 123.8487, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 1.268, 'epoch': 0.23}\n",
      "{'loss': 1.0446, 'learning_rate': 4.363161124189387e-06, 'epoch': 0.24}\n",
      "{'eval_loss': 1.0056387186050415, 'eval_runtime': 123.883, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 1.267, 'epoch': 0.24}\n",
      "{'loss': 1.0405, 'learning_rate': 4.309335095262675e-06, 'epoch': 0.25}\n",
      "{'eval_loss': 1.001731514930725, 'eval_runtime': 123.8564, 'eval_samples_per_second': 5.07, 'eval_steps_per_second': 1.268, 'epoch': 0.25}\n",
      "{'loss': 1.0366, 'learning_rate': 4.253687219265803e-06, 'epoch': 0.26}\n",
      "{'eval_loss': 0.9976800680160522, 'eval_runtime': 123.8848, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 1.267, 'epoch': 0.26}\n",
      "{'loss': 1.0329, 'learning_rate': 4.196273528892831e-06, 'epoch': 0.27}\n",
      "{'eval_loss': 0.9940397143363953, 'eval_runtime': 124.0299, 'eval_samples_per_second': 5.063, 'eval_steps_per_second': 1.266, 'epoch': 0.27}\n",
      "{'loss': 1.0292, 'learning_rate': 4.137151834863213e-06, 'epoch': 0.28}\n",
      "{'eval_loss': 0.9902209639549255, 'eval_runtime': 123.8173, 'eval_samples_per_second': 5.072, 'eval_steps_per_second': 1.268, 'epoch': 0.28}\n",
      "{'loss': 1.0252, 'learning_rate': 4.076381667711306e-06, 'epoch': 0.29}\n",
      "{'eval_loss': 0.9868155121803284, 'eval_runtime': 123.6233, 'eval_samples_per_second': 5.08, 'eval_steps_per_second': 1.27, 'epoch': 0.29}\n",
      "{'loss': 1.0216, 'learning_rate': 4.014024217844167e-06, 'epoch': 0.3}\n",
      "{'eval_loss': 0.9835496544837952, 'eval_runtime': 123.8615, 'eval_samples_per_second': 5.07, 'eval_steps_per_second': 1.268, 'epoch': 0.3}\n",
      "{'loss': 1.0187, 'learning_rate': 3.950142273927996e-06, 'epoch': 0.31}\n",
      "{'eval_loss': 0.9802442193031311, 'eval_runtime': 123.7139, 'eval_samples_per_second': 5.076, 'eval_steps_per_second': 1.269, 'epoch': 0.31}\n",
      "{'loss': 1.0156, 'learning_rate': 3.8848001596652765e-06, 'epoch': 0.32}\n",
      "{'eval_loss': 0.9772619009017944, 'eval_runtime': 123.7394, 'eval_samples_per_second': 5.075, 'eval_steps_per_second': 1.269, 'epoch': 0.32}\n",
      "{'loss': 1.0124, 'learning_rate': 3.8180636690262565e-06, 'epoch': 0.33}\n",
      "{'eval_loss': 0.9743096232414246, 'eval_runtime': 123.9436, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.33}\n",
      "{'loss': 1.0094, 'learning_rate': 3.7500000000000005e-06, 'epoch': 0.34}\n",
      "{'eval_loss': 0.9714598655700684, 'eval_runtime': 123.9777, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.266, 'epoch': 0.34}\n",
      "{'loss': 1.0067, 'learning_rate': 3.6806776869317074e-06, 'epoch': 0.35}\n",
      "{'eval_loss': 0.9686780571937561, 'eval_runtime': 124.0017, 'eval_samples_per_second': 5.064, 'eval_steps_per_second': 1.266, 'epoch': 0.35}\n",
      "{'loss': 1.004, 'learning_rate': 3.6101665315144357e-06, 'epoch': 0.36}\n",
      "{'eval_loss': 0.9660308361053467, 'eval_runtime': 123.9381, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.36}\n",
      "{'loss': 1.0013, 'learning_rate': 3.5385375325047167e-06, 'epoch': 0.37}\n",
      "{'eval_loss': 0.9635266065597534, 'eval_runtime': 123.9239, 'eval_samples_per_second': 5.068, 'eval_steps_per_second': 1.267, 'epoch': 0.37}\n",
      "{'loss': 0.999, 'learning_rate': 3.4658628142328215e-06, 'epoch': 0.38}\n",
      "{'eval_loss': 0.9609703421592712, 'eval_runtime': 123.7244, 'eval_samples_per_second': 5.076, 'eval_steps_per_second': 1.269, 'epoch': 0.38}\n",
      "{'loss': 0.9964, 'learning_rate': 3.39221555397968e-06, 'epoch': 0.39}\n",
      "{'eval_loss': 0.9588955640792847, 'eval_runtime': 124.1435, 'eval_samples_per_second': 5.059, 'eval_steps_per_second': 1.265, 'epoch': 0.39}\n",
      "{'loss': 0.994, 'learning_rate': 3.3176699082935546e-06, 'epoch': 0.4}\n",
      "{'eval_loss': 0.9565281867980957, 'eval_runtime': 124.1346, 'eval_samples_per_second': 5.059, 'eval_steps_per_second': 1.265, 'epoch': 0.4}\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.9919, 'learning_rate': 3.2423009383206876e-06, 'epoch': 0.41}\n",
      "{'eval_loss': 0.954394519329071, 'eval_runtime': 123.9596, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.267, 'epoch': 0.41}\n",
      "{'loss': 0.9896, 'learning_rate': 3.1661845342250874e-06, 'epoch': 0.42}\n",
      "{'eval_loss': 0.9523203372955322, 'eval_runtime': 124.2233, 'eval_samples_per_second': 5.055, 'eval_steps_per_second': 1.264, 'epoch': 0.42}\n",
      "{'loss': 0.9876, 'learning_rate': 3.089397338773569e-06, 'epoch': 0.43}\n",
      "{'eval_loss': 0.9502907395362854, 'eval_runtime': 123.9925, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.266, 'epoch': 0.43}\n",
      "{'loss': 0.9856, 'learning_rate': 3.012016670162977e-06, 'epoch': 0.44}\n",
      "{'eval_loss': 0.9484127759933472, 'eval_runtime': 124.0111, 'eval_samples_per_second': 5.064, 'eval_steps_per_second': 1.266, 'epoch': 0.44}\n",
      "{'loss': 0.9836, 'learning_rate': 2.9341204441673267e-06, 'epoch': 0.45}\n",
      "{'eval_loss': 0.946636438369751, 'eval_runtime': 124.1452, 'eval_samples_per_second': 5.059, 'eval_steps_per_second': 1.265, 'epoch': 0.45}\n",
      "{'loss': 0.9816, 'learning_rate': 2.8557870956832135e-06, 'epoch': 0.46}\n",
      "{'eval_loss': 0.9447596669197083, 'eval_runtime': 124.0331, 'eval_samples_per_second': 5.063, 'eval_steps_per_second': 1.266, 'epoch': 0.46}\n",
      "{'loss': 0.9802, 'learning_rate': 2.7770954997525277e-06, 'epoch': 0.47}\n",
      "{'eval_loss': 0.9431812167167664, 'eval_runtime': 123.9808, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.266, 'epoch': 0.47}\n",
      "{'loss': 0.9783, 'learning_rate': 2.6981248921419713e-06, 'epoch': 0.48}\n",
      "{'eval_loss': 0.9414991736412048, 'eval_runtime': 124.0209, 'eval_samples_per_second': 5.064, 'eval_steps_per_second': 1.266, 'epoch': 0.48}\n",
      "{'loss': 0.9765, 'learning_rate': 2.6189547895593565e-06, 'epoch': 0.49}\n",
      "{'eval_loss': 0.9398535490036011, 'eval_runtime': 124.1283, 'eval_samples_per_second': 5.059, 'eval_steps_per_second': 1.265, 'epoch': 0.49}\n",
      "{'loss': 0.975, 'learning_rate': 2.53966490958702e-06, 'epoch': 0.5}\n",
      "{'eval_loss': 0.9385186433792114, 'eval_runtime': 124.2335, 'eval_samples_per_second': 5.055, 'eval_steps_per_second': 1.264, 'epoch': 0.5}\n",
      "{'loss': 0.9733, 'learning_rate': 2.4603350904129802e-06, 'epoch': 0.51}\n",
      "{'eval_loss': 0.9370834231376648, 'eval_runtime': 124.1383, 'eval_samples_per_second': 5.059, 'eval_steps_per_second': 1.265, 'epoch': 0.51}\n",
      "{'loss': 0.9721, 'learning_rate': 2.3810452104406444e-06, 'epoch': 0.52}\n",
      "{'eval_loss': 0.9356757402420044, 'eval_runtime': 124.1974, 'eval_samples_per_second': 5.056, 'eval_steps_per_second': 1.264, 'epoch': 0.52}\n",
      "{'loss': 0.9711, 'learning_rate': 2.3018751078580287e-06, 'epoch': 0.53}\n",
      "{'eval_loss': 0.9344212412834167, 'eval_runtime': 123.8493, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 1.268, 'epoch': 0.53}\n",
      "{'loss': 0.9694, 'learning_rate': 2.2229045002474727e-06, 'epoch': 0.54}\n",
      "{'eval_loss': 0.9332072138786316, 'eval_runtime': 124.0052, 'eval_samples_per_second': 5.064, 'eval_steps_per_second': 1.266, 'epoch': 0.54}\n",
      "{'loss': 0.9685, 'learning_rate': 2.1442129043167877e-06, 'epoch': 0.55}\n",
      "{'eval_loss': 0.9320834279060364, 'eval_runtime': 124.039, 'eval_samples_per_second': 5.063, 'eval_steps_per_second': 1.266, 'epoch': 0.55}\n",
      "{'loss': 0.9673, 'learning_rate': 2.0658795558326745e-06, 'epoch': 0.56}\n",
      "{'eval_loss': 0.9309589266777039, 'eval_runtime': 124.1598, 'eval_samples_per_second': 5.058, 'eval_steps_per_second': 1.264, 'epoch': 0.56}\n",
      "{'loss': 0.9659, 'learning_rate': 1.987983329837024e-06, 'epoch': 0.57}\n",
      "{'eval_loss': 0.9299888014793396, 'eval_runtime': 123.9483, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.57}\n",
      "{'loss': 0.965, 'learning_rate': 1.9106026612264316e-06, 'epoch': 0.58}\n",
      "{'eval_loss': 0.9289148449897766, 'eval_runtime': 123.9691, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.266, 'epoch': 0.58}\n",
      "{'loss': 0.9638, 'learning_rate': 1.833815465774913e-06, 'epoch': 0.59}\n",
      "{'eval_loss': 0.9279102683067322, 'eval_runtime': 124.0809, 'eval_samples_per_second': 5.061, 'eval_steps_per_second': 1.265, 'epoch': 0.59}\n",
      "{'loss': 0.9627, 'learning_rate': 1.7576990616793139e-06, 'epoch': 0.6}\n",
      "{'eval_loss': 0.9270073771476746, 'eval_runtime': 124.1486, 'eval_samples_per_second': 5.058, 'eval_steps_per_second': 1.265, 'epoch': 0.6}\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.9617, 'learning_rate': 1.6823300917064462e-06, 'epoch': 0.61}\n",
      "{'eval_loss': 0.9262464046478271, 'eval_runtime': 125.2198, 'eval_samples_per_second': 5.015, 'eval_steps_per_second': 1.254, 'epoch': 0.61}\n",
      "{'loss': 0.961, 'learning_rate': 1.6077844460203207e-06, 'epoch': 0.62}\n",
      "{'eval_loss': 0.9253119230270386, 'eval_runtime': 123.9808, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.266, 'epoch': 0.62}\n",
      "{'loss': 0.9603, 'learning_rate': 1.5341371857671782e-06, 'epoch': 0.63}\n",
      "{'eval_loss': 0.9245556592941284, 'eval_runtime': 124.047, 'eval_samples_per_second': 5.063, 'eval_steps_per_second': 1.266, 'epoch': 0.63}\n",
      "{'loss': 0.9592, 'learning_rate': 1.4614624674952843e-06, 'epoch': 0.64}\n",
      "{'eval_loss': 0.9237270355224609, 'eval_runtime': 124.0216, 'eval_samples_per_second': 5.064, 'eval_steps_per_second': 1.266, 'epoch': 0.64}\n",
      "{'loss': 0.9586, 'learning_rate': 1.3898334684855647e-06, 'epoch': 0.65}\n",
      "{'eval_loss': 0.9231045246124268, 'eval_runtime': 123.9747, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.266, 'epoch': 0.65}\n",
      "{'loss': 0.9578, 'learning_rate': 1.3193223130682937e-06, 'epoch': 0.66}\n",
      "{'eval_loss': 0.9223971962928772, 'eval_runtime': 124.0637, 'eval_samples_per_second': 5.062, 'eval_steps_per_second': 1.265, 'epoch': 0.66}\n",
      "{'loss': 0.9572, 'learning_rate': 1.2500000000000007e-06, 'epoch': 0.67}\n",
      "{'eval_loss': 0.9216920733451843, 'eval_runtime': 123.9724, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.266, 'epoch': 0.67}\n",
      "{'loss': 0.9564, 'learning_rate': 1.181936330973744e-06, 'epoch': 0.68}\n",
      "{'eval_loss': 0.9212658405303955, 'eval_runtime': 124.1863, 'eval_samples_per_second': 5.057, 'eval_steps_per_second': 1.264, 'epoch': 0.68}\n",
      "{'loss': 0.9558, 'learning_rate': 1.1151998403347245e-06, 'epoch': 0.69}\n",
      "{'eval_loss': 0.9206823110580444, 'eval_runtime': 123.9608, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.267, 'epoch': 0.69}\n",
      "{'loss': 0.9551, 'learning_rate': 1.049857726072005e-06, 'epoch': 0.7}\n",
      "{'eval_loss': 0.9200760126113892, 'eval_runtime': 124.0922, 'eval_samples_per_second': 5.061, 'eval_steps_per_second': 1.265, 'epoch': 0.7}\n",
      "{'loss': 0.9551, 'learning_rate': 9.85975782155834e-07, 'epoch': 0.71}\n",
      "{'eval_loss': 0.9195927977561951, 'eval_runtime': 123.8614, 'eval_samples_per_second': 5.07, 'eval_steps_per_second': 1.268, 'epoch': 0.71}\n",
      "{'loss': 0.9543, 'learning_rate': 9.236183322886946e-07, 'epoch': 0.72}\n",
      "{'eval_loss': 0.9191869497299194, 'eval_runtime': 124.1269, 'eval_samples_per_second': 5.059, 'eval_steps_per_second': 1.265, 'epoch': 0.72}\n",
      "{'loss': 0.9536, 'learning_rate': 8.628481651367876e-07, 'epoch': 0.73}\n",
      "{'eval_loss': 0.9188320636749268, 'eval_runtime': 123.9587, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.267, 'epoch': 0.73}\n",
      "{'loss': 0.9538, 'learning_rate': 8.037264711071699e-07, 'epoch': 0.74}\n",
      "{'eval_loss': 0.9183357357978821, 'eval_runtime': 124.1821, 'eval_samples_per_second': 5.057, 'eval_steps_per_second': 1.264, 'epoch': 0.74}\n",
      "{'loss': 0.953, 'learning_rate': 7.463127807341966e-07, 'epoch': 0.75}\n",
      "{'eval_loss': 0.9180741906166077, 'eval_runtime': 123.9234, 'eval_samples_per_second': 5.068, 'eval_steps_per_second': 1.267, 'epoch': 0.75}\n",
      "{'loss': 0.9526, 'learning_rate': 6.906649047373246e-07, 'epoch': 0.76}\n",
      "{'eval_loss': 0.9176530838012695, 'eval_runtime': 124.0692, 'eval_samples_per_second': 5.062, 'eval_steps_per_second': 1.265, 'epoch': 0.76}\n",
      "{'loss': 0.9524, 'learning_rate': 6.368388758106134e-07, 'epoch': 0.77}\n",
      "{'eval_loss': 0.9173218607902527, 'eval_runtime': 123.9147, 'eval_samples_per_second': 5.068, 'eval_steps_per_second': 1.267, 'epoch': 0.77}\n",
      "{'loss': 0.9521, 'learning_rate': 5.848888922025553e-07, 'epoch': 0.78}\n",
      "{'eval_loss': 0.9171381592750549, 'eval_runtime': 123.9176, 'eval_samples_per_second': 5.068, 'eval_steps_per_second': 1.267, 'epoch': 0.78}\n",
      "{'loss': 0.9515, 'learning_rate': 5.348672631430319e-07, 'epoch': 0.79}\n",
      "{'eval_loss': 0.9168953895568848, 'eval_runtime': 125.3284, 'eval_samples_per_second': 5.011, 'eval_steps_per_second': 1.253, 'epoch': 0.79}\n",
      "{'loss': 0.9516, 'learning_rate': 4.868243561723535e-07, 'epoch': 0.8}\n",
      "{'eval_loss': 0.9165998101234436, 'eval_runtime': 124.1136, 'eval_samples_per_second': 5.06, 'eval_steps_per_second': 1.265, 'epoch': 0.8}\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
      "{'loss': 0.9508, 'learning_rate': 4.4080854642541833e-07, 'epoch': 0.81}\n",
      "{'eval_loss': 0.9163998961448669, 'eval_runtime': 124.2329, 'eval_samples_per_second': 5.055, 'eval_steps_per_second': 1.264, 'epoch': 0.81}\n",
      "{'loss': 0.9508, 'learning_rate': 3.9686616792204677e-07, 'epoch': 0.82}\n",
      "{'eval_loss': 0.9162197113037109, 'eval_runtime': 124.0209, 'eval_samples_per_second': 5.064, 'eval_steps_per_second': 1.266, 'epoch': 0.82}\n",
      "{'loss': 0.9509, 'learning_rate': 3.5504146691255736e-07, 'epoch': 0.83}\n",
      "{'eval_loss': 0.9160265326499939, 'eval_runtime': 124.0204, 'eval_samples_per_second': 5.064, 'eval_steps_per_second': 1.266, 'epoch': 0.83}\n",
      "{'loss': 0.9507, 'learning_rate': 3.153765573255377e-07, 'epoch': 0.84}\n",
      "{'eval_loss': 0.9158884882926941, 'eval_runtime': 124.11, 'eval_samples_per_second': 5.06, 'eval_steps_per_second': 1.265, 'epoch': 0.84}\n",
      "{'loss': 0.9504, 'learning_rate': 2.779113783626916e-07, 'epoch': 0.85}\n",
      "{'eval_loss': 0.9157422184944153, 'eval_runtime': 123.6379, 'eval_samples_per_second': 5.079, 'eval_steps_per_second': 1.27, 'epoch': 0.85}\n",
      "{'loss': 0.95, 'learning_rate': 2.4268365428344737e-07, 'epoch': 0.86}\n",
      "{'eval_loss': 0.915573239326477, 'eval_runtime': 124.0705, 'eval_samples_per_second': 5.062, 'eval_steps_per_second': 1.265, 'epoch': 0.86}\n",
      "{'loss': 0.9503, 'learning_rate': 2.0972885641982605e-07, 'epoch': 0.87}\n",
      "{'eval_loss': 0.9154959321022034, 'eval_runtime': 124.0367, 'eval_samples_per_second': 5.063, 'eval_steps_per_second': 1.266, 'epoch': 0.87}\n",
      "{'loss': 0.9504, 'learning_rate': 1.790801674598186e-07, 'epoch': 0.88}\n",
      "{'eval_loss': 0.915383517742157, 'eval_runtime': 124.1181, 'eval_samples_per_second': 5.06, 'eval_steps_per_second': 1.265, 'epoch': 0.88}\n",
      "{'loss': 0.95, 'learning_rate': 1.507684480352292e-07, 'epoch': 0.89}\n",
      "{'eval_loss': 0.9153462052345276, 'eval_runtime': 123.917, 'eval_samples_per_second': 5.068, 'eval_steps_per_second': 1.267, 'epoch': 0.89}\n",
      "{'loss': 0.9498, 'learning_rate': 1.2482220564763669e-07, 'epoch': 0.9}\n",
      "{'eval_loss': 0.915296196937561, 'eval_runtime': 123.9509, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.9}\n",
      "{'loss': 0.9497, 'learning_rate': 1.0126756596375687e-07, 'epoch': 0.91}\n",
      "{'eval_loss': 0.9152749180793762, 'eval_runtime': 123.9718, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 1.266, 'epoch': 0.91}\n",
      "{'loss': 0.9498, 'learning_rate': 8.012824650910938e-08, 'epoch': 0.92}\n",
      "{'eval_loss': 0.9151374101638794, 'eval_runtime': 123.9976, 'eval_samples_per_second': 5.065, 'eval_steps_per_second': 1.266, 'epoch': 0.92}\n",
      "{'loss': 0.95, 'learning_rate': 6.142553278648239e-08, 'epoch': 0.93}\n",
      "{'eval_loss': 0.9152341485023499, 'eval_runtime': 124.1874, 'eval_samples_per_second': 5.057, 'eval_steps_per_second': 1.264, 'epoch': 0.93}\n",
      "{'loss': 0.9493, 'learning_rate': 4.5178256843233235e-08, 'epoch': 0.94}\n",
      "{'eval_loss': 0.9151111841201782, 'eval_runtime': 123.9323, 'eval_samples_per_second': 5.067, 'eval_steps_per_second': 1.267, 'epoch': 0.94}\n",
      "{'loss': 0.9498, 'learning_rate': 3.1402778309014284e-08, 'epoch': 0.95}\n",
      "{'eval_loss': 0.9150907397270203, 'eval_runtime': 124.6903, 'eval_samples_per_second': 5.036, 'eval_steps_per_second': 1.259, 'epoch': 0.95}\n",
      "{'loss': 0.9497, 'learning_rate': 2.011296792301165e-08, 'epoch': 0.96}\n",
      "{'eval_loss': 0.9150511026382446, 'eval_runtime': 124.1809, 'eval_samples_per_second': 5.057, 'eval_steps_per_second': 1.264, 'epoch': 0.96}\n",
      "{'loss': 0.9499, 'learning_rate': 1.132019356728853e-08, 'epoch': 0.97}\n",
      "{'eval_loss': 0.9151297211647034, 'eval_runtime': 124.1206, 'eval_samples_per_second': 5.06, 'eval_steps_per_second': 1.265, 'epoch': 0.97}\n",
      "{'loss': 0.9494, 'learning_rate': 5.033308820289185e-09, 'epoch': 0.98}\n",
      "{'eval_loss': 0.9150569438934326, 'eval_runtime': 124.2472, 'eval_samples_per_second': 5.054, 'eval_steps_per_second': 1.264, 'epoch': 0.98}\n",
      "{'loss': 0.9498, 'learning_rate': 1.2586440420372936e-09, 'epoch': 0.99}\n",
      "{'eval_loss': 0.9151034951210022, 'eval_runtime': 124.0748, 'eval_samples_per_second': 5.061, 'eval_steps_per_second': 1.265, 'epoch': 0.99}\n",
      "{'loss': 0.9497, 'learning_rate': 0.0, 'epoch': 1.0}\n",
      "{'eval_loss': 0.9151884317398071, 'eval_runtime': 124.1832, 'eval_samples_per_second': 5.057, 'eval_steps_per_second': 1.264, 'epoch': 1.0}\n",
      "{'train_runtime': 534567.6029, 'train_samples_per_second': 1.197, 'train_steps_per_second': 0.019, 'train_loss': 1.0212602653503418, 'epoch': 1.0}\n",
      "Loading best peft model from ./checkpoints/checkpoint-10000 (score: 0.9151884317398071).\n",
      "Saving last checkpoint of the model\n",
      "CPU times: user 57min 41s, sys: 10min 51s, total: 1h 8min 32s\n",
      "Wall time: 6d 4h 29min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python finetune-starcoder-1b.py\\\n",
    "--model_path=\"bigcode/starcoderbase-1b\"\\\n",
    "--seq_length=512\\\n",
    "--batch_size=2\\\n",
    "--eos_token_id=0\\\n",
    "--save_freq=2000\\\n",
    "--seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1cf1f6c-348e-4967-8801-cd2fd729f647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to bigcode/starcoderbase-1b-merged\n",
      "CPU times: user 247 ms, sys: 58.6 ms, total: 306 ms\n",
      "Wall time: 40.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python merge_peft_adapters.py\\\n",
    "--base_model_name_or_path=\"bigcode/starcoderbase-1b\"\\\n",
    "--peft_model_path=\"./checkpoints/final_checkpoint/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f79c8",
   "metadata": {},
   "source": [
    "# \n",
    "## Evaluate fine-tuned model with QALD-9-plus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bdbcc5",
   "metadata": {},
   "source": [
    "\n",
    "### Load fine-tuned checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ae1851d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['optimizer.pt',\n",
       " 'scheduler.pt',\n",
       " 'pytorch_model.bin',\n",
       " 'adapter_model.bin',\n",
       " 'README.md',\n",
       " 'rng_state.pth',\n",
       " 'trainer_state.json',\n",
       " 'training_args.bin',\n",
       " 'adapter_config.json']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir(\"./checkpoints/checkpoint-2000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ca2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint=\"bigcode/starcoderbase-1b-merged\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, use_auth_token=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d88b10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for:\n",
      "# What is the foundation of diocese of birobidzhan?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "Answer: select?x where{dbr:Birobidzhan dbo:foundation?x1.?x1 dbo:dbrId?x }<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"\"\"\n",
    "# write a SPARQL query for:\n",
    "# What is the foundation of diocese of birobidzhan ?\n",
    "\n",
    "# use following prefixes:\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11afa8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for:\n",
      "# What is the capital of Canada?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "Answer: select?x where{dbr:Canada dbo:capital?x1.?x1 dbo:capital?x }<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"\"\"\n",
    "# write a SPARQL query for:\n",
    "# What is the capital of Canada ?\n",
    "\n",
    "# use following prefixes:\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f5b4566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for:\n",
      "# What was the population of Italy in 2000?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "Answer: select?x where{dbr:Italy dbo:population?x1.?x1 dbo:year?x }<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"\"\"\n",
    "# write a SPARQL query for:\n",
    "# What was the population of Italy in 2000 ?\n",
    "\n",
    "# use following prefixes:\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47279862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for:\n",
      "# What is the population of France?\n",
      "\n",
      "# use following prefixes:\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "Answer: select?x where{dbr:France dbo:population?x }<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"\"\"\n",
    "# write a SPARQL query for:\n",
    "# What is the population of France ?\n",
    "\n",
    "# use following prefixes:\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2c752",
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo\n",
    "prompt.stirp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f61354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b6e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e915867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '1',\n",
       " 'question': [{'language': 'en', 'string': 'List all boardgames by GMT.'},\n",
       "  {'language': 'de', 'string': 'Liste die Brettspiele von GMT auf.'},\n",
       "  {'language': 'de', 'string': 'Zeige mir alle Brettspiele von GMT.'},\n",
       "  {'language': 'ru', 'string': 'Перечислите все игры GMT.'},\n",
       "  {'language': 'lt', 'string': 'Išvardinkite visus stalo žaidimus pagal GMT.'},\n",
       "  {'language': 'uk', 'string': 'Перерахуйте всі ігри GMT.'},\n",
       "  {'language': 'lt', 'string': 'Išvardykite visus GMT žaidimus.'},\n",
       "  {'language': 'fr', 'string': 'Listez tous les jeux de société de GMT.'},\n",
       "  {'language': 'es',\n",
       "   'string': '¿Qué juegos de mesa fueron hechos por GMT?',\n",
       "   'keywords': 'juego de mesa ,  GMT '}],\n",
       " 'query': {'sparql': 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> SELECT ?uri WHERE { ?uri dbo:publisher res:GMT_Games }'},\n",
       " 'answers': [{'head': {'link': [], 'vars': ['uri']},\n",
       "   'results': {'bindings': [{'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Chandragupta_(board_game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Fields_of_Fire_(game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Sword_of_Rome'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Paths_of_Glory_(board_game)'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Commands_&_Colors:_Ancients'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Labyrinth:_The_War_on_Terror,_2001_–_%3F'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': 'http://dbpedia.org/resource/Twilight_Struggle'}},\n",
       "     {'uri': {'type': 'uri',\n",
       "       'value': \"http://dbpedia.org/resource/Washington's_War\"}}]}}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('data/qald_9_plus_train_dbpedia.json', 'r') as f:\n",
    "    qald_9_plus_data = json.load(f)\n",
    "    \n",
    "qald_9_plus_data['questions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "434c25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 pairs extracted from train set:  \n",
      "\n",
      "List all boardgames by GMT.\n",
      "\n",
      " PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      " PREFIX res: <http://dbpedia.org/resource/>\n",
      " PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
      " SELECT ?uri WHERE { ?uri dbo:publisher res:GMT_Games }\n"
     ]
    }
   ],
   "source": [
    "# extracting pairs of question/sparql    \n",
    "    \n",
    "nl_questions, sparql_queries =[],[]\n",
    "\n",
    "for data in qald_9_plus_data['questions']:\n",
    "    nl_questions.append(\n",
    "        next((item['string'] for item in data['question'] if item['language'] == 'en'), None)\n",
    "    )\n",
    "    sparql_queries.append(data['query']['sparql'])\n",
    "    \n",
    "\n",
    "print(f'{len(nl_questions)} pairs extracted from train set: ', \"\\n\")\n",
    "print(nl_questions[0])\n",
    "print('\\n', sparql_queries[0].replace(\">\", '>\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e84d503",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "### Calculate BELUE score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e301444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model_name_or_path\", type=str)\n",
    "    parser.add_argument(\"--data_path\", type=str, default=\"/\")\n",
    "    parser.add_argument(\"--metric_name\", type=str, default=\"bleu\")\n",
    "    parser.add_argument(\"--input_column_name\", type=str, default=\"prompt\")\n",
    "    parser.add_argument(\"--output_column_name\", type=str, default=\"completion\")\n",
    "    return parser.parse_args()\n",
    "\n",
    " \n",
    "    \n",
    "def read_dataset(path):\n",
    "    data = pd.read_csv(path)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def generate_SPARQL(model, tokenizer, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=250,\n",
    "        num_beams=5,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    return tokenizer.decode(outputs[0])\n",
    "\n",
    "\n",
    "\n",
    "def calculate_bleu(actual, generated, metric_name):\n",
    "    bleu_metric = load_metric(metric_name)\n",
    "    bleu_score = bleu_metric.compute(predictions=[generated.split()], references=[[actual.split()]])\n",
    "    return bleu_score['bleu']\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \n",
    "    args = get_args()\n",
    "\n",
    "    data = read_dataset(args.data_path)\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.model_name_or_path)\n",
    "    tokenizer.pad_token = tokenizer.eos_token   # Set pad token to EOS token\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args.model_name_or_path, use_auth_token=True).to(device)\n",
    "\n",
    "    \n",
    "    print(f'\\n\\nTokenizer and model successfully loaded on:\\t{device}')\n",
    "    \n",
    "    print(f'\\nCalculating scores with <{args.metric_name}> as evaluation metric\\n...'+\"\\n\"*2)\n",
    "    \n",
    "    results = []\n",
    "    total_bleu_score = 0\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        prompt, actual_sparql = row[args.input_column_name], row[args.output_column_name]\n",
    "        generated_sparql = generate_SPARQL(model, tokenizer, prompt)\n",
    "\n",
    "        bleu_score = calculate_bleu(actual_sparql, generated_sparql, args.metric_name)\n",
    "\n",
    "        results.append((prompt, actual_sparql, generated_sparql, bleu_score))\n",
    "\n",
    "        total_bleu_score += bleu_score\n",
    "\n",
    "    average_bleu_score = total_bleu_score / len(data)\n",
    "\n",
    "    \n",
    "    print(\"\\n\"+\"*\"*50 +f\"Results for {args.model_name_or_path}:\\n\", results)\n",
    "    print(f\"\\nAverage BLEU score for {args.model_name_or_path}: \", average_bleu_score)\n",
    "\n",
    "\n",
    "    # delete model & tokenizer and clear cache \n",
    "    del model\n",
    "    del tokenizer\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    main()            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b841791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/nspm_100k_test.csv\")\n",
    "\n",
    "df_sample = df_test.sample(n=500, random_state=0)\n",
    "df_sample.to_csv(\"data/nspm_test_500.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0a6a84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO:root:Loading tokenizer and model on cuda:0.\n",
      "\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpq78wczpo\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpq78wczpo/_remote_module_non_scriptable.py\n",
      "\n",
      "Calculating scores with <bleu> as evaluation metric\n",
      "...\n",
      "\n",
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/mehrzad/repos/mehrz/dbpedia/neural-qa-mehrzadshm/gsoc/mehrzad/evaluate_model.py:47: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(metric_name)\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mehrzad/repos/mehrz/dbpedia/neural-qa-mehrzadshm/gsoc/mehrzad/evaluate_model.py\", line 111, in <module>\n",
      "    main()            \n",
      "  File \"/home/mehrzad/repos/mehrz/dbpedia/neural-qa-mehrzadshm/gsoc/mehrzad/evaluate_model.py\", line 87, in main\n",
      "    generated_sparql = generate_SPARQL(model, tokenizer, prompt)\n",
      "  File \"/home/mehrzad/repos/mehrz/dbpedia/neural-qa-mehrzadshm/gsoc/mehrzad/evaluate_model.py\", line 33, in generate_SPARQL\n",
      "    outputs = model.generate(\n",
      "  File \"/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1611, in generate\n",
      "    return self.beam_search(\n",
      "  File \"/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2962, in beam_search\n",
      "    beam_outputs = beam_scorer.process(\n",
      "  File \"/home/mehrzad/anaconda3/envs/dbpedia/lib/python3.10/site-packages/transformers/generation/beam_search.py\", line 238, in process\n",
      "    if self._done[batch_idx]:\n",
      "KeyboardInterrupt\n",
      "CPU times: user 1.69 s, sys: 272 ms, total: 1.96 s\n",
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python evaluate_model.py\\\n",
    "--model_name_or_path=\"bigcode/starcoderbase-1b-merged\"\\\n",
    "--data_path=\"./data/nspm_test_500.csv\"\\\n",
    "--metric_name=\"bleu\"\\\n",
    "--verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566c4f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading tokenizer and model on cuda:0.\n",
      "\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpa78o8_5c\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpa78o8_5c/_remote_module_non_scriptable.py\n",
      "\n",
      "Calculating scores with <bleu> as evaluation metric\n",
      "...\n",
      "\n",
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/mehrzad/repos/mehrz/dbpedia/neural-qa-mehrzadshm/gsoc/mehrzad/evaluate_model.py:52: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(metric_name)\n",
      "\n",
      "********************************************************************************\n",
      "Results written to eval_results.csv\n",
      "\n",
      "Average BLEU score for 500 test samples:  0.01604976731943413\n",
      "CPU times: user 8.28 s, sys: 1.46 s, total: 9.74 s\n",
      "Wall time: 12min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python evaluate_model.py\\\n",
    "--model_name_or_path=\"bigcode/starcoderbase-1b-merged\"\\\n",
    "--data_path=\"./data/nspm_test_500.csv\"\\\n",
    "--metric_name=\"bleu\"\\\n",
    "--report_file_name=\"eval_results_02\"\\\n",
    "--verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029c19d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading tokenizer and model on cuda:0.\n",
      "\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmp__s_mmtm\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmp__s_mmtm/_remote_module_non_scriptable.py\n",
      "\n",
      "Calculating scores with <bleu> as evaluation metric\n",
      "...\n",
      "\n",
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/mehrzad/repos/mehrz/dbpedia/neural-qa-mehrzadshm/gsoc/mehrzad/evaluate_model.py:52: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(metric_name)\n",
      "\n",
      "********************************************************************************\n",
      "Results written to eval_results.csv\n",
      "\n",
      "Average BLEU score for 500 test samples:  0.0\n",
      "CPU times: user 19.3 s, sys: 2.81 s, total: 22.1 s\n",
      "Wall time: 39min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python evaluate_model.py\\\n",
    "--model_name_or_path=\"bigcode/starcoderbase-1b\"\\\n",
    "--data_path=\"./data/nspm_test_500.csv\"\\\n",
    "--metric_name=\"bleu\"\\\n",
    "--report_file_name=\"eval_results_starcoder_base_1b\"\\\n",
    "--verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c4a5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPARQLPostProcessor:\n",
    "    \n",
    "    ## TODO\n",
    "\n",
    "    # deal with spaces\n",
    "\n",
    "\n",
    "    # for now, remove things based on \"Answer:\" token\n",
    "    def remove_from_token(self, generated_output, reference_token=\"Answer:\"):\n",
    "        return generated_output.replace(reference_token, '').strip()\n",
    "\n",
    "    \n",
    "    def post_process(self, query):\n",
    "        query = self.remove_from_token(query)\n",
    "        #\n",
    "        #\n",
    "        return query\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_SPARQL(model, tokenizer, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    input_ids = inputs[\"input_ids\"].to(model.device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(model.device)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=250,\n",
    "        num_beams=5,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        early_stopping=True\n",
    "    ) \n",
    "    \n",
    "    return tokenizer.decode(outputs[0])\n",
    "\n",
    "\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token   # Set pad token to EOS token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bca00da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# write a SPARQL query for;\n",
      "# what is the population of Italy?\n",
      "# use following prefixes:\n",
      "\n",
      "PREFIX dbr: <http://dbpedia.org/resource/>\n",
      "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
      "\n",
      "Answer: select?x where{dbr:Italy dbo:population?x }<|endoftext|>\n",
      "\n",
      "After\n",
      "select?x where{dbr:Italy dbo:population?x }<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "# write a SPARQL query for;\n",
    "# what is the population of Italy?\n",
    "# use following prefixes:\n",
    "\n",
    "PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "post_processor = SPARQLPostProcessor()\n",
    "\n",
    "generated_sparql = generate_SPARQL(model, tokenizer, prompt)\n",
    "print(generated_sparql)\n",
    "\n",
    "print(\"\\nAfter\")\n",
    "\n",
    "clean_generated_sparql = post_processor.post_process(generated_sparql[len(prompt):])\n",
    "print(clean_generated_sparql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6eba957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# write a SPARQL query for;\\n# what is the population of Italy?\\n# use following prefixes:\\n\\nPREFIX dbr: <http://dbpedia.org/resource/>\\nPREFIX dbo: <http://dbpedia.org/ontology/>\\n\\nAnswer: select?x where{dbr:Italy dbo:population?x }<|endoftext|>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(generated_sparql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4e3171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer: select?x where{dbr:Italy dbo:population?x }<|endoftext|>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sparql[len(prompt):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a42ee241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# write a SPARQL query for;\\n# what is the population of Italy?\\n# use following prefixes:\\n\\nPREFIX dbr: <http://dbpedia.org/resource/>\\nPREFIX dbo: <http://dbpedia.org/ontology/>\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e462d0-66d4-40ba-8266-8593c2728950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b070a3b-041b-4312-b6d0-e102ed3667d6",
   "metadata": {},
   "source": [
    "# \n",
    "## Evaluate 2nd fine-tuned model with QALD-9-plus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37318fe6-99b7-4230-9b87-e02249d4cac7",
   "metadata": {},
   "source": [
    "\n",
    "### Load fine-tuned checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "182dfd62-8766-4396-8f49-eddee4c8f927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "INFO:root:Loading tokenizer and model on cuda:0.\n",
      "\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpqw9bxtp8\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpqw9bxtp8/_remote_module_non_scriptable.py\n",
      "\n",
      "Calculating scores with <bleu> as evaluation metric\n",
      "...\n",
      "\n",
      "\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/evaluate_model.py:53: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(metric_name)\n",
      "INFO:root:Processed 0 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.4111336169005197\n",
      "INFO:root:Processed 200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 400 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.3549481056010052\n",
      "INFO:root:Processed 700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5\n",
      "INFO:root:Processed 900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 1000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 1100 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 1200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 1300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.2998221389342337\n",
      "INFO:root:Processed 1400 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 1500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 1600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 1700 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 1800 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 1900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 2000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 2100 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 2200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 2300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 2400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 2500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 2600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 2700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 2800 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 2900 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 3000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 3100 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 3200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 3300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 3400 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 3500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 3600 rows. BLEU Score - Generated: 0.2750524266743666, Post-Processed: 0.588979818781874\n",
      "INFO:root:Processed 3700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 3800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 3900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5\n",
      "INFO:root:Processed 4000 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 4100 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 4200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 4300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 4400 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 4500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 4600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 4700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.37991784282579627\n",
      "INFO:root:Processed 4800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 4900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 5000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 5100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 5200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 5300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 5400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 5500 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 5600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5698363775444273\n",
      "INFO:root:Processed 5700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 5800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 5900 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 6000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 6100 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 6200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 6300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 6400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 6500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5\n",
      "INFO:root:Processed 6600 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 6700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 6800 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 6900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 7000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 7100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.4111336169005197\n",
      "INFO:root:Processed 7200 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 7300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 7400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 7500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 7600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 7700 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 7800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 7900 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 8000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 8100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 8200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 8300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 8400 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 8500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 8600 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 8700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.2998221389342337\n",
      "INFO:root:Processed 8800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5698363775444273\n",
      "INFO:root:Processed 8900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 9000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 9100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 9200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 9300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 9400 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 9500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5\n",
      "INFO:root:Processed 9600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 9700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 9800 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 9900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 10000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 10100 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 10200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 10300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 10400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 10500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 10600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.2998221389342337\n",
      "INFO:root:Processed 10700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 10800 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 10900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 11000 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 11100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 11200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 11300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 11400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 11500 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 0.0\n",
      "INFO:root:Processed 11600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 11700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.3862752974508186\n",
      "INFO:root:Processed 11800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 11900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 12000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.25712008025141314\n",
      "INFO:root:Processed 12100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5698363775444273\n",
      "INFO:root:Processed 12200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5\n",
      "INFO:root:Processed 12300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 12400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 12500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 12600 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 12700 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 12800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 12900 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 13000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 13100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 13200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 13300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 13400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 13500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 13600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 13700 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 13800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 13900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 14000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 14100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 14200 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 14300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 14400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 14500 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 14600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 14700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 14800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 14900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 15000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5\n",
      "INFO:root:Processed 15100 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 15200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 15300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 15400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 15500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.3862752974508186\n",
      "INFO:root:Processed 15600 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 15700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.4639247374454443\n",
      "INFO:root:Processed 15800 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 15900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 16000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 16100 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 16200 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 16300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 16400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 16500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 16600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 16700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 16800 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 16900 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 17000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.33010083098515036\n",
      "INFO:root:Processed 17100 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 17200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 17300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.2998221389342337\n",
      "INFO:root:Processed 17400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 17500 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 17600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 17700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 17800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 17900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.2998221389342337\n",
      "INFO:root:Processed 18000 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 18100 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 18200 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 18300 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 18400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 18500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 18600 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 18700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5341735956899847\n",
      "INFO:root:Processed 18800 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 18900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.5946035575013605\n",
      "INFO:root:Processed 19000 rows. BLEU Score - Generated: 0.5081327481546147, Post-Processed: 1.0\n",
      "INFO:root:Processed 19100 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 19200 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 19300 rows. BLEU Score - Generated: 0.0, Post-Processed: 1.0\n",
      "INFO:root:Processed 19400 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 19500 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 19600 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 19700 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "INFO:root:Processed 19800 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.3862752974508186\n",
      "INFO:root:Processed 19900 rows. BLEU Score - Generated: 0.0, Post-Processed: 0.0\n",
      "\n",
      "********************************************************************************\n",
      "Results written to eval_results_starcoder_base_1b_02.csv\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/evaluate_model.py\", line 191, in <module>\n",
      "    main()            \n",
      "    ^^^^^^\n",
      "  File \"/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/evaluate_model.py\", line 177, in main\n",
      "    print(f\"\\nAverage BLEU score for {len(data)} test samples: \", average_bleu_score)\n",
      "                                                                  ^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'average_bleu_score' is not defined. Did you mean: 'average_bleu_score_raw'?\n",
      "CPU times: user 2min 29s, sys: 29.4 s, total: 2min 58s\n",
      "Wall time: 6h 9min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!python evaluate_model.py\\\n",
    "--model_name_or_path=\"bigcode/starcoderbase-1b-merged\"\\\n",
    "--data_path=\"./data/nspm-fine-tuning/test.csv\"\\\n",
    "--metric_name=\"bleu\"\\\n",
    "--report_file_name=\"eval_results_starcoder_base_1b_02\"\\\n",
    "--verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f76d705b-5b9f-414d-88ba-0cad258da516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Actual SPARQL</th>\n",
       "      <th>Generated SPARQL</th>\n",
       "      <th>BLEU Score (Generated)</th>\n",
       "      <th>Post-Processed SPARQL</th>\n",
       "      <th>BLEU Score (Post-Processed)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># write a SPARQL query for:\\n# What is the Lin...</td>\n",
       "      <td>select ?x where{dbr:Karl_Marx dbo:birthPlace ?...</td>\n",
       "      <td>\\nAnswer: select?x where{dbr:Karl_Marx dbo:bir...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select ?x where{dbr:Karl_Marx dbo:birthPlace ?...</td>\n",
       "      <td>0.330101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># write a SPARQL query for:\\n# Is diocesan col...</td>\n",
       "      <td>ask where{dbr:Morgan_Newman dbo:school dbr:Dio...</td>\n",
       "      <td>\\nAnswer: ask where{dbr:Morgan_Newman dbo:scho...</td>\n",
       "      <td>0.508133</td>\n",
       "      <td>ask where{dbr:Morgan_Newman dbo:school dbr:Dio...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># write a SPARQL query for:\\n# What is the cou...</td>\n",
       "      <td>select ?x where{dbr:Canário dbo:birthPlace ?x1...</td>\n",
       "      <td>\\nAnswer: select?x where{dbr:Canário dbo:birth...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select ?x where{dbr:Canário dbo:birthPlace ?x1...</td>\n",
       "      <td>0.534174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># write a SPARQL query for:\\n# What is the por...</td>\n",
       "      <td>select ?x where{dbr:Stella_Bonasera dbo:portra...</td>\n",
       "      <td>\\nAnswer: select?x where{dbr:Stella_Bonasera d...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select ?x where{dbr:Stella_Bonasera dbo:portra...</td>\n",
       "      <td>0.534174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td># write a SPARQL query for:\\n# Has south afric...</td>\n",
       "      <td>ask where{dbr:South_African_Class_16E dbo:rebu...</td>\n",
       "      <td>\\nAnswer: ask where{dbr:South_African_Class_16...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>ask where{dbr:South_African_Class_16E dbo:rebu...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td># write a SPARQL query for:\\n# How many diamet...</td>\n",
       "      <td>select count(*) as ?x where{dbr:Volterra_(crat...</td>\n",
       "      <td>\\nAnswer: select count(*) as?x where{dbr:Volte...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select count(*) as ?x where{dbr:Volterra dbo:d...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td># write a SPARQL query for:\\n# How is hyatt re...</td>\n",
       "      <td>select ?x where{dbr:Hyatt_Regency_Chicago dbo:...</td>\n",
       "      <td>\\nAnswer: select?x where{dbr:Hotel_Inglaterra ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select ?x where{dbr:Hotel_Inglaterra dbo:floor...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td># write a SPARQL query for:\\n# Who is thomas d...</td>\n",
       "      <td>select ?x where{dbr:Thomas_Dudley dbo:father ?...</td>\n",
       "      <td>\\nAnswer: select?x where{dbr:Thomas_Dudley dbo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select ?x where{dbr:Thomas_Dudley dbo:father ?...</td>\n",
       "      <td>0.317622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td># write a SPARQL query for:\\n# What are most o...</td>\n",
       "      <td>select count(*) as ?x where{dbr:Schuylkill_Ars...</td>\n",
       "      <td>\\nAnswer: select?x where{dbr:Schuylkill_Arsena...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select ?x where{dbr:Schuylkill_Arsenal_Railroa...</td>\n",
       "      <td>0.569836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td># write a SPARQL query for:\\n# How many next e...</td>\n",
       "      <td>select count(*) as ?x where{dbr:Alpine_skiing_...</td>\n",
       "      <td>\\nAnswer: select count(*) as?x where{dbr:Alpin...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>select count(*) as ?x where{dbr:Alpine_skiing_...</td>\n",
       "      <td>0.510029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Prompt  \\\n",
       "0      # write a SPARQL query for:\\n# What is the Lin...   \n",
       "1      # write a SPARQL query for:\\n# Is diocesan col...   \n",
       "2      # write a SPARQL query for:\\n# What is the cou...   \n",
       "3      # write a SPARQL query for:\\n# What is the por...   \n",
       "4      # write a SPARQL query for:\\n# Has south afric...   \n",
       "...                                                  ...   \n",
       "19995  # write a SPARQL query for:\\n# How many diamet...   \n",
       "19996  # write a SPARQL query for:\\n# How is hyatt re...   \n",
       "19997  # write a SPARQL query for:\\n# Who is thomas d...   \n",
       "19998  # write a SPARQL query for:\\n# What are most o...   \n",
       "19999  # write a SPARQL query for:\\n# How many next e...   \n",
       "\n",
       "                                           Actual SPARQL  \\\n",
       "0      select ?x where{dbr:Karl_Marx dbo:birthPlace ?...   \n",
       "1      ask where{dbr:Morgan_Newman dbo:school dbr:Dio...   \n",
       "2      select ?x where{dbr:Canário dbo:birthPlace ?x1...   \n",
       "3      select ?x where{dbr:Stella_Bonasera dbo:portra...   \n",
       "4      ask where{dbr:South_African_Class_16E dbo:rebu...   \n",
       "...                                                  ...   \n",
       "19995  select count(*) as ?x where{dbr:Volterra_(crat...   \n",
       "19996  select ?x where{dbr:Hyatt_Regency_Chicago dbo:...   \n",
       "19997  select ?x where{dbr:Thomas_Dudley dbo:father ?...   \n",
       "19998  select count(*) as ?x where{dbr:Schuylkill_Ars...   \n",
       "19999  select count(*) as ?x where{dbr:Alpine_skiing_...   \n",
       "\n",
       "                                        Generated SPARQL  \\\n",
       "0      \\nAnswer: select?x where{dbr:Karl_Marx dbo:bir...   \n",
       "1      \\nAnswer: ask where{dbr:Morgan_Newman dbo:scho...   \n",
       "2      \\nAnswer: select?x where{dbr:Canário dbo:birth...   \n",
       "3      \\nAnswer: select?x where{dbr:Stella_Bonasera d...   \n",
       "4      \\nAnswer: ask where{dbr:South_African_Class_16...   \n",
       "...                                                  ...   \n",
       "19995  \\nAnswer: select count(*) as?x where{dbr:Volte...   \n",
       "19996  \\nAnswer: select?x where{dbr:Hotel_Inglaterra ...   \n",
       "19997  \\nAnswer: select?x where{dbr:Thomas_Dudley dbo...   \n",
       "19998  \\nAnswer: select?x where{dbr:Schuylkill_Arsena...   \n",
       "19999  \\nAnswer: select count(*) as?x where{dbr:Alpin...   \n",
       "\n",
       "       BLEU Score (Generated)  \\\n",
       "0                    0.000000   \n",
       "1                    0.508133   \n",
       "2                    0.000000   \n",
       "3                    0.000000   \n",
       "4                    0.000000   \n",
       "...                       ...   \n",
       "19995                0.000000   \n",
       "19996                0.000000   \n",
       "19997                0.000000   \n",
       "19998                0.000000   \n",
       "19999                0.000000   \n",
       "\n",
       "                                   Post-Processed SPARQL  \\\n",
       "0      select ?x where{dbr:Karl_Marx dbo:birthPlace ?...   \n",
       "1      ask where{dbr:Morgan_Newman dbo:school dbr:Dio...   \n",
       "2      select ?x where{dbr:Canário dbo:birthPlace ?x1...   \n",
       "3      select ?x where{dbr:Stella_Bonasera dbo:portra...   \n",
       "4      ask where{dbr:South_African_Class_16E dbo:rebu...   \n",
       "...                                                  ...   \n",
       "19995  select count(*) as ?x where{dbr:Volterra dbo:d...   \n",
       "19996  select ?x where{dbr:Hotel_Inglaterra dbo:floor...   \n",
       "19997  select ?x where{dbr:Thomas_Dudley dbo:father ?...   \n",
       "19998  select ?x where{dbr:Schuylkill_Arsenal_Railroa...   \n",
       "19999  select count(*) as ?x where{dbr:Alpine_skiing_...   \n",
       "\n",
       "       BLEU Score (Post-Processed)  \n",
       "0                         0.330101  \n",
       "1                         1.000000  \n",
       "2                         0.534174  \n",
       "3                         0.534174  \n",
       "4                         1.000000  \n",
       "...                            ...  \n",
       "19995                     0.500000  \n",
       "19996                     0.000000  \n",
       "19997                     0.317622  \n",
       "19998                     0.569836  \n",
       "19999                     0.510029  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"eval_results_starcoder_base_1b_02.csv\")\n",
    "df\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "89267d0a-8b21-415f-8316-e622001e2a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Descriptive Statistics for BLEU Scores (Generated):\n",
      "count    20000.000000\n",
      "mean         0.029052\n",
      "std          0.116592\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          0.759836\n",
      "Name: BLEU Score (Generated), dtype: float64\n",
      "\n",
      "\n",
      "Descriptive Statistics for BLEU Scores (Post-Processed):\n",
      "count    20000.000000\n",
      "mean         0.437779\n",
      "std          0.413116\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.386275\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: BLEU Score (Post-Processed), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"Descriptive Statistics for BLEU Scores (Generated):\")\n",
    "print(df['BLEU Score (Generated)'].describe())\n",
    "print(\"\\n\")\n",
    "print(\"Descriptive Statistics for BLEU Scores (Post-Processed):\")\n",
    "print(df['BLEU Score (Post-Processed)'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dd261ee7-8121-4932-a462-3c3f8b72add7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:     # Is the emerald number of parking spaces of claridge icon ? \n",
      "\n",
      "Actual:     ask where{dbr:Claridge_Icon dbo:numberOfParkingSpaces dbr:The_Emerald_(building) }\n",
      "Processed:  ask where{dbr:Claridge_Icon dbo:numberOfParkingSpaces dbr:Emerald }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did the george houston house have the NRHP reference number ? \n",
      "\n",
      "Actual:     ask where{dbr:George_Houston_House dbo:nrhpReferenceNumber ?x }\n",
      "Processed:  ask where{dbr:The_George_Houston_House dbo:nrhpReferenceNumber ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # How should I know the ingredient names for mache ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Mache_(food) dbo:ingredientName ?x }\n",
      "Processed:  select ?x where{dbr:Mache dbo:ingredientName ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Which was the year of the first ascent of laila peak and michael peak ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Laila_Peak_(Haramosh_Valley) dbo:firstAscentYear ?x . dbr:Michael_Peak dbo:firstAscentYear ?x }\n",
      "Processed:  select ?x where{dbr:Michael_Peak dbo:firstAscentYear ?x. dbr:Laila_Peak dbo:firstAscentYear ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is soviet union date of liberation of ravensbrück concentration camp ? \n",
      "\n",
      "Actual:     ask where{dbr:Ravensbrück_concentration_camp dbo:liberationDate Soviet Union, 30 April 1945 }\n",
      "Processed:  ask where{dbr:Ravensbrück_Concentration_Camp dbo:dateOfLiberation dbr:Soviet_Union }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the using country of boliviano ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Boliviano_(1864–1963) dbo:usingCountry ?x }\n",
      "Processed:  select ?x where{dbr:Boliviano dbo:usingCountry ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Does bishop's college have a Campus Type ? \n",
      "\n",
      "Actual:     ask where{dbr:Bishop's_College,_Colombo dbo:campusType ?x }\n",
      "Processed:  ask where{dbr:Bishop's_College dbo:campusType ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is beer actually lone tree brewery product ? \n",
      "\n",
      "Actual:     ask where{dbr:Lone_Tree_Brewery dbo:product dbr:Beer }\n",
      "Processed:  ask where{dbr:Lone_Tree_Brewery dbo:product ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is it the kgeg ICAO location of spokane international airport ? \n",
      "\n",
      "Actual:     ask where{dbr:Spokane_International_Airport dbo:icaoLocationIdentifier KGEG }\n",
      "Processed:  ask where{dbr:Spokane_International_Airport dbo:icaoLocation dbr:KGEG }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is mercedes-benz om660 engine's compression rate ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Mercedes-Benz_OM660_engine dbo:compressionRatio ?x }\n",
      "Processed:  select ?x where{dbr:Mercedes-Benz_OM660_engine dbo:compressionRate ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did the corot-11b have an orbital period of 180 years ? \n",
      "\n",
      "Actual:     ask where{dbr:CoRoT-11b dbo:orbitalPeriod ?x }\n",
      "Processed:  ask where{dbr:Corot-11b dbo:orbitalPeriod ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is sam olver relative of william andrews clark jr. ? \n",
      "\n",
      "Actual:     ask where{dbr:William_Andrews_Clark_Jr. dbo:relative dbr:Sam_Olver }\n",
      "Processed:  ask where{dbr:William_Andrews_Clark_Jr dbo:relative dbr:Sam_Olver }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the difference between arbane and jonadel and how can they be formed ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Arbane dbo:species ?x . dbr:Jonadel dbo:species ?x }\n",
      "Processed:  select ?x where{dbr:Arbane dbo:formation ?x. dbr:Jonadel dbo:formation ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Who is the chief executive officer of ontario hockey league and septa suburban division bus routes ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Ontario_Hockey_League dbo:ceo ?x . dbr:SEPTA_Suburban_Division_bus_routes dbo:ceo ?x }\n",
      "Processed:  select ?x where{dbr:Septa_Suburban_Division_Bus_Routes dbo:chiefExecutiveOfficer ?x. dbr:Ontario_Hockey_League dbo:chiefExecutiveOfficer ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # nan \n",
      "\n",
      "Actual:     select count(*) as ?x where{<A> dbo:albedo ?x }\n",
      "Processed:  select ?x where{<A> dbo:spouse ?x1. ?x1 dbo:birthPlace ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the jean lucas as well as mike sparken race ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Jean_Lucas_(racing_driver) dbo:races ?x . dbr:Mike_Sparken dbo:races ?x }\n",
      "Processed:  select ?x where{dbr:Mike_Sparken dbo:race ?x. dbr:Jean_Lucas dbo:race ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the curse of the pharaohs Dewey Decimal Classification of to see every bird on earth ? \n",
      "\n",
      "Actual:     ask where{dbr:To_See_Every_Bird_on_Earth dbo:dcc dbr:The_Curse_of_the_Pharaohs_(novel) }\n",
      "Processed:  select ?x where{dbr:To_See_Every_Bird_on_Earth dbo:dcc ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is 136th indiana infantry regiment an 2nd cavalry division ? \n",
      "\n",
      "Actual:     ask where{dbr:2nd_Cavalry_Division_(Belgium) dbo:disbanded dbr:136th_Indiana_Infantry_Regiment }\n",
      "Processed:  ask where{dbr:136th_Indiana_Infantry_Regiment dbo:division dbr:2nd_Cavalry }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the orbital period of hd 212301 b and 1993 mf ? \n",
      "\n",
      "Actual:     select ?x where{dbr:(5836) _1993_MF dbo:orbitalPeriod ?x . dbr:HD_212301_b dbo:orbitalPeriod ?x }\n",
      "Processed:  select ?x where{dbr:HD_212301_b dbo:orbitalPeriod ?x. dbr:1993_MF dbo:orbitalPeriod ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is mordella metallica kingdom of <B> or mordella metallica kingdom ? \n",
      "\n",
      "Actual:     ask where{<B> dbo:kingdom dbr:Mordella_metallica }\n",
      "Processed:  ask where{dbr:Mordella_metallica dbo:kingdom dbr:Kingdom_of_Mordella }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is being victor's death year ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Being_Victor dbo:person ?x1 . ?x1 dbo:deathYear ?x }\n",
      "Processed:  select ?x where{dbr:Victor_(cricketer) dbo:deathPlace ?x1. ?x1 dbo:yearOfDeath ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the reporting mark of ontario southland railway and kelowna pacific railway ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Kelowna_Pacific_Railway dbo:reportingMark ?x . dbr:Ontario_Southland_Railway dbo:reportingMark ?x }\n",
      "Processed:  select ?x where{dbr:Ontario_Southland_Railway dbo:reportingMark ?x. dbr:Kelowna_Pacific_Railway dbo:reportingMark ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # How many Shrine were created in the history of sadasiva brahmendra and anna maria rubatto ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Sadasiva_Brahmendra dbo:majorShrine ?x . dbr:Anna_Maria_Rubatto dbo:majorShrine ?x }\n",
      "Processed:  select count(*) as ?x where{dbr:Sadasiva_Brahmendra dbo:shrine ?x. dbr:Anna_Maria_Rubatto dbo:shrine ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Who are the doctoral students at lothar collatz and duncan haldane ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Lothar_Collatz dbo:doctoralStudent ?x . dbr:Duncan_Haldane dbo:doctoralStudent ?x }\n",
      "Processed:  select ?x where{dbr:Duncan_Haldane dbo:doctoralStudent ?x. dbr:Lothar_Collatz dbo:doctoralStudent ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did anthony lapaglia really have a relative ? \n",
      "\n",
      "Actual:     ask where{dbr:Anthony_LaPaglia dbo:relative ?x }\n",
      "Processed:  ask where{dbr:Anthony_Lapaglia dbo:relative ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is the wilderness society subsidiary of zenimax media ? \n",
      "\n",
      "Actual:     ask where{dbr:ZeniMax_Media dbo:subsidiary dbr:The_Wilderness_Society_(United_States) }\n",
      "Processed:  ask where{dbr:Zenimax_Media dbo:subsidiary dbr:Wilderness_Society }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What's the serving size of vienna sausage albap ? \n",
      "\n",
      "Actual:     ask where{dbr:Vienna_sausage dbo:servingSize dbr:Albap }\n",
      "Processed:  select ?x where{dbr:Vienna_Sausage_Albap dbo:servingSize ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the distance laps of 2018 marrakesh eprix ? \n",
      "\n",
      "Actual:     select ?x where{dbr:2018_Marrakesh_ePrix dbo:distanceLaps ?x }\n",
      "Processed:  select ?x where{dbr:2018_Marrakesh_Eprix dbo:distanceLaps ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Who is shane warne: the musical song and why ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Shane_Warne:_The_Musical dbo:musicBy ?x }\n",
      "Processed:  select ?x where{dbr:Shane_Warne:_The_Musical_Song dbo:artist ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is 1948 san remo grand prix \"The First Driver\" Country on 1950 bari grand prix ? \n",
      "\n",
      "Actual:     ask where{dbr:1950_Bari_Grand_Prix dbo:firstDriverCountry dbr:1948_San_Remo_Grand_Prix }\n",
      "Processed:  ask where{dbr:1948_San_Remo_Grand_Prix dbo:firstDriverCountry dbr:1950_Bari_Grand_Prix }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the tumisa eruption date ? \n",
      "\n",
      "Actual:     ask where{<B> dbo:eruptionYear dbr:Tumisa }\n",
      "Processed:  select ?x where{dbr:Tumisa dbo:eruptionDate ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What are the sister stations of kfmh as well as woly ? \n",
      "\n",
      "Actual:     select ?x where{dbr:WOLY_(AM) dbo:sisterStation ?x . dbr:KFMH dbo:sisterStation ?x }\n",
      "Processed:  select ?x where{dbr:KFMH dbo:sisterStation ?x. dbr:WOLY dbo:sisterStation ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the average class size in doamna stanca national college ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Doamna_Stanca_National_College_(Satu_Mare) dbo:averageClassSize ?x }\n",
      "Processed:  select ?x where{dbr:Doamna_Stanca_National_College dbo:averageClassSize ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the band member of ghost ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Ghost_(Swedish_band) dbo:bandMember ?x }\n",
      "Processed:  select ?x where{dbr:Ghost_(band) dbo:bandMember ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Who are good trainers for beethoven ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Beethoven_(horse) dbo:trainer ?x }\n",
      "Processed:  select ?x where{dbr:Beethoven dbo:trainer ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is testaverage of sma negeri 1 yogyakarta ? \n",
      "\n",
      "Actual:     select ?x where{dbr:SMA_Negeri_1_Yogyakarta dbo:testaverage ?x }\n",
      "Processed:  select ?x where{dbr:SMA_Negeri_1_Yogyakarta dbo:testAverage ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did sociedade desportiva juazeirense actually have chairman of the company ? \n",
      "\n",
      "Actual:     ask where{dbr:Sociedade_Desportiva_Juazeirense dbo:chairmanTitle ?x }\n",
      "Processed:  ask where{dbr:Sociedade_desportiva_Juazeirense dbo:chairman ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Who is partner of ninaithale inikkum presenter ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Ninaithale_Inikkum_(talk_show) dbo:presenter ?x1 . ?x1 dbo:partner ?x }\n",
      "Processed:  select ?x where{dbr:Ninaithale_Inikkum dbo:presenter ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the compression ratio between oldsmobile diesel engine and mercedes-benz m04 engine ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Mercedes-Benz_M04_engine dbo:compressionRatio ?x . dbr:Oldsmobile_Diesel_engine dbo:compressionRatio ?x }\n",
      "Processed:  select ?x where{dbr:Oldsmobile_diesel_engine dbo:compressionRatio ?x. dbr:Mercedes-Benz_M04_engine dbo:compressionRatio ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What are three brothers's location in area ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Three_Brothers_(Yosemite) dbo:locatedInArea ?x1 . ?x1 dbo:demonym ?x }\n",
      "Processed:  select ?x where{dbr:Three_Brothers dbo:location ?x1. ?x1 dbo:area ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did dm-crypt have a size X ? \n",
      "\n",
      "Actual:     ask where{dbr:Dm-crypt dbo:fileSize ?x }\n",
      "Processed:  ask where{dbr:DM-Crypt dbo:sizeX ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Will rage be the motive of murder of dean shillingsworth ? \n",
      "\n",
      "Actual:     ask where{dbr:Murder_of_Dean_Shillingsworth dbo:motive Rage }\n",
      "Processed:  ask where{dbr:Dean_Shillingsworth dbo:motive dbr:Rage_(play) }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the weight of mazda premacy hydrogen re hybrid ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Mazda_Premacy_Hydrogen_RE_Hybrid dbo:weight ?x }\n",
      "Processed:  select ?x where{dbr:Mazda_Premacy_Hydrogen_Re_Hybrid dbo:weight ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Was Chinese train company yodo line carrying railway rolling stock ? \n",
      "\n",
      "Actual:     ask where{dbr:Yodo_Line dbo:railwayRollingStock ?x }\n",
      "Processed:  ask where{dbr:Yodo_line dbo:carryingRailway dbr:Chinese_train_company }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the area rural of rambani dialect ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Rambani_dialect dbo:spokenIn ?x1 . ?x1 dbo:areaRural ?x }\n",
      "Processed:  select ?x where{dbr:Rambani_dialect dbo:areaRural ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the administrative collectivity of both vollmershain and weißenohe ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Weißenohe dbo:administrativeCollectivity ?x . dbr:Vollmershain dbo:administrativeCollectivity ?x }\n",
      "Processed:  select ?x where{dbr:Vollmershain dbo:administrativeCollectivity ?x. dbr:Weißenohe dbo:administrativeCollectivity ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # How much is the damage amount of 1985 mexico city earthquake ? \n",
      "\n",
      "Actual:     select ?x where{dbr:1985_Mexico_City_earthquake dbo:damage ?x }\n",
      "Processed:  select ?x where{dbr:1985_Mexico_City_earthquake dbo:damageAmount ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did woi have broadcast network ? \n",
      "\n",
      "Actual:     ask where{dbr:WOI_(AM) dbo:broadcastNetwork ?x1 . ?x1 dbo:broadcastNetwork ?x }\n",
      "Processed:  ask where{dbr:WOI dbo:broadcastNetwork ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Which was the highest place of death in frédéric charles jean gingins de la sarraz ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Frédéric_Charles_Jean_Gingins_de_la_Sarraz dbo:deathPlace ?x1 . ?x1 dbo:highestPlace ?x }\n",
      "Processed:  select ?x where{dbr:Frédéric_Charles_Jean_Gingins_de_la_Sarraz dbo:highestPlaceOfDeath ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the equestrian at the 1932 summer olympics – team jumping game ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Equestrian_at_the_1932_Summer_Olympics_–_Team_jumping dbo:games ?x }\n",
      "Processed:  select ?x where{dbr:1932_Summer_Olympics_–_Team_Jumping dbo:equestrian ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What are railway rolling stock for kualanamu airport rail link ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Kualanamu_Airport_Rail_Link dbo:railwayRollingStock ?x }\n",
      "Processed:  select ?x where{dbr:Kualanamu_Airport dbo:railwayRollingStock ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the city type of benton county and jeff davis county ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Benton_County,_Mississippi dbo:cityType ?x . dbr:Jeff_Davis_County,_Texas dbo:cityType ?x }\n",
      "Processed:  select ?x where{dbr:Benton_County,_Pennsylvania dbo:cityType ?x. dbr:Jeff_Davis_County,_Pennsylvania dbo:cityType ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is ututo frequently updated of turtlebot ? \n",
      "\n",
      "Actual:     ask where{dbr:TurtleBot dbo:frequentlyUpdated dbr:Ututo }\n",
      "Processed:  ask where{dbr:Turtlebot dbo:frequentlyUpdated dbr:Ututo }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # How do I connect rail gauge aller valley railway and lersøen–østerport line to the rail gauge ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Aller_Valley_Railway dbo:railGauge ?x . dbr:Lersøen–Østerport_Line dbo:railGauge ?x }\n",
      "Processed:  select ?x where{dbr:Lersøen–Østerport_line dbo:railGauge ?x. dbr:Rail_Gauge_Aller_Valley dbo:railGauge ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the area of canavaggia and cangey ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Cangey dbo:area ?x . dbr:Canavaggia dbo:area ?x }\n",
      "Processed:  select ?x where{dbr:Canavaggia dbo:area ?x. dbr:Cangey dbo:area ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did 1995 us open have champion in single female ? \n",
      "\n",
      "Actual:     ask where{dbr:1995_US_Open_(tennis) dbo:championInSingleFemale ?x }\n",
      "Processed:  ask where{dbr:1995_US_Open dbo:championInSingleFemale ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is crvie4 CODEN of cardiology in review ? \n",
      "\n",
      "Actual:     ask where{dbr:Cardiology_in_Review dbo:coden CRVIE4 }\n",
      "Processed:  ask where{dbr:Cardiology_in_Review dbo:coden dbr:CRVIE4 }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is 800 kressmannia epoch ? \n",
      "\n",
      "Actual:     ask where{dbr:800_Kressmannia dbo:epoch }\n",
      "Processed:  ask where{dbr:800_Kressmannia dbo:epoch ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the ISO region code of jinzhou as well as balsthal ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Jinzhou dbo:isoCodeRegion ?x . dbr:Balsthal dbo:isoCodeRegion ?x }\n",
      "Processed:  select ?x where{dbr:Jinzhou dbo:isoRegionCode ?x. dbr:Balsthal dbo:isoRegionCode ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did blake rosenthal have a relationship with a recent boyfriend ? \n",
      "\n",
      "Actual:     ask where{dbr:Blake_Rosenthal dbo:currentPartner ?x }\n",
      "Processed:  ask where{dbr:Blake_Rosenhall dbo:boyfriend ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the quote from the biography of store urevatn ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Store_Urevatn dbo:quote ?x }\n",
      "Processed:  select ?x where{dbr:Store_Urevatn dbo:biography ?x1. ?x1 dbo:quote ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is taxi stand other serving lines of budhni railway station ? \n",
      "\n",
      "Actual:     ask where{dbr:Budhni_railway_station dbo:otherServingLines Taxi stand, auto stand }\n",
      "Processed:  ask where{dbr:Budhni_railway_station dbo:otherServingLines dbr:Taxi_stand }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What's joyless street editing and what is beyond the law editing ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Beyond_the_Law_(1968_American_film) dbo:editing ?x . dbr:Joyless_Street dbo:editing ?x }\n",
      "Processed:  select ?x where{dbr:Joyless_Street dbo:editing ?x. dbr:Beyond_the_Law dbo:editing ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is legislature of revival lê dynasty ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Revival_Lê_dynasty dbo:legislature ?x }\n",
      "Processed:  select ?x where{dbr:Revival_Lê dbo:legislature ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the diameter of one middle range multi-purpose missile ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Middle_range_Multi-Purpose_missile dbo:diameter ?x }\n",
      "Processed:  select ?x where{dbr:One_Middle_Range_Multi-Purpose_Missile dbo:diameter ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # How do you see the mouth of river ciornovăț ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Ciornovăț dbo:riverMouth ?x }\n",
      "Processed:  select ?x where{dbr:River_Ciornovăț dbo:mouthPlace ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the city type on union county ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Union_County,_New_Mexico dbo:cityType ?x }\n",
      "Processed:  select ?x where{dbr:Union_County,_Ohio dbo:cityType ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the gini coefficient of history of the islamic republic of iran and eswatini ? \n",
      "\n",
      "Actual:     select ?x where{dbr:History_of_the_Islamic_Republic_of_Iran dbo:giniCoefficient ?x . dbr:Eswatini dbo:giniCoefficient ?x }\n",
      "Processed:  select ?x where{dbr:Eswatini dbo:giniCoefficient ?x. dbr:History_of_the_Islamic_Republic_of_Iran dbo:giniCoefficient ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is 2.7e+07 size of sobrr ? \n",
      "\n",
      "Actual:     ask where{dbr:Sobrr dbo:fileSize 2.7e+07 }\n",
      "Processed:  ask where{dbr:Sobrr dbo:fileSize 2 . 7e+07 }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the fare zone of st. ilgen/sandhausen station as well as heiligenstadt station ? \n",
      "\n",
      "Actual:     select ?x where{dbr:St._Ilgen/Sandhausen_station dbo:fareZone ?x . dbr:Heiligenstadt_station_(Vienna_U-Bahn) dbo:fareZone ?x }\n",
      "Processed:  select ?x where{dbr:Sandhausen_station dbo:fareZone ?x. dbr:St . _Ilgen dbo:fareZone ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is 1945439, a synonym for anadolu university ? \n",
      "\n",
      "Actual:     ask where{dbr:Anadolu_University dbo:other 1945439 }\n",
      "Processed:  select ?x where{dbr:Anadolu_University dbo:synonym ?x. <B> dbo:synonym ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did despina have an apparent magnitude ? What do you think ? \n",
      "\n",
      "Actual:     ask where{dbr:Despina_(moon) dbo:apparentMagnitude ?x }\n",
      "Processed:  ask where{dbr:Despina dbo:apparentMagnitude ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What are the old records of stan stolte and mark stoops ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Mark_Stoops dbo:currentRecord ?x . dbr:Stan_Stolte dbo:currentRecord ?x }\n",
      "Processed:  select ?x where{dbr:Stan_Stoops dbo:oldRecord ?x. dbr:Mark_Stoops dbo:oldRecord ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Which is the most number of locations of production company eliminators ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Eliminators_(2016_film) dbo:productionCompany ?x1 . ?x1 dbo:numberOfLocations ?x}order by desc (?x) limit 1\n",
      "Processed:  select ?x where{dbr:Eliminators_(film) dbo:productionCompany ?x1. ?x1 dbo:numberOfLocations ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the largest number of undergraduate students of college of jeremy robinson ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Jeremy_Robinson_(golfer) dbo:college ?x1 . ?x1 dbo:numberOfUndergraduateStudents ?x}order by desc (?x) limit 1\n",
      "Processed:  select ?x where{dbr:College_of_Jeremy_Robinson dbo:numberOfUndergraduateStudents ?x1. ?x1 dbo:largest ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is book of love going to be on carson city ? \n",
      "\n",
      "Actual:     ask where{dbr:Carson_City_(film) dbo:starring dbr:Book_of_Love_(2002_film) }\n",
      "Processed:  ask where{dbr:Book_of_Love_Going_to_Be_on_Carson_City dbo:isPartOfMuseum ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is uss quillback laying down a new uss kearsarge ? \n",
      "\n",
      "Actual:     ask where{dbr:USS_Kearsarge_(BB-5) dbo:layingDown dbr:USS_Quillback_(SS-424) }\n",
      "Processed:  ask where{dbr:USS_Kearsarge dbo:layingDown dbr:USS_Quillback }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the trading name for first interstate bancsystem ? \n",
      "\n",
      "Actual:     select ?x where{dbr:First_Interstate_BancSystem dbo:tradingName ?x }\n",
      "Processed:  select ?x where{dbr:First_Interstate_Bancsystem dbo:tradingName ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the NRHP Reference Number of monument square historic district ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Monument_Square_Historic_District_(Charlestown,_Boston,_Massachusetts) dbo:nrhpReferenceNumber ?x }\n",
      "Processed:  select ?x where{dbr:Monument_Square_Historic_District dbo:nrhpReferenceNumber ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is uss roper laying down a new río segura ? \n",
      "\n",
      "Actual:     ask where{dbr:Río_Segura dbo:layingDown dbr:USS_Roper_(DD-147) }\n",
      "Processed:  ask where{dbr:USS_Roper dbo:layingDown ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # How much weight did roger wilson have ? \n",
      "\n",
      "Actual:     ask where{dbr:Roger_Wilson_(rugby_union) dbo:weight ?x }\n",
      "Processed:  select count(*) as ?x where{dbr:Roger_Wilson dbo:weight ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What are no. 156 squadron raf's aircraft bombers ? \n",
      "\n",
      "Actual:     select ?x where{dbr:No._156_Squadron_RAF dbo:commandStructure ?x1 . ?x1 dbo:aircraftBomber ?x }\n",
      "Processed:  select ?x where{dbr:No . _156_Squadron_RAF dbo:aircraftBomber ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is the population metro of 17844 of timrå ? \n",
      "\n",
      "Actual:     ask where{dbr:Timrå dbo:populationMetro 17844 }\n",
      "Processed:  ask where{dbr:17844_of_Timrå dbo:populationMetro ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is david walker's first race ? What races will there be ? \n",
      "\n",
      "Actual:     select ?x where{dbr:David_Walker_(racing_driver) dbo:firstRace ?x1 . ?x1 dbo:course ?x }\n",
      "Processed:  select ?x where{dbr:David_Walker dbo:firstRace ?x1. ?x1 dbo:races ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Did ponder have foal date ? \n",
      "\n",
      "Actual:     ask where{dbr:Ponder_(horse) dbo:foalDate ?x }\n",
      "Processed:  ask where{dbr:Ponder dbo:foalDate ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the area of catchment of green lake as well as ulsoor lake ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Green_Lake_(Wisconsin) dbo:areaOfCatchment ?x . dbr:Ulsoor_Lake dbo:areaOfCatchment ?x }\n",
      "Processed:  select ?x where{dbr:Green_Lake dbo:areaOfCatchment ?x. dbr:Ulsooor_Lake dbo:areaOfCatchment ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is biological really interested in eridge green ? \n",
      "\n",
      "Actual:     ask where{dbr:Eridge_Green dbo:interest Biological }\n",
      "Processed:  ask where{dbr:Eridge_Green dbo:interest ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is pakistan muslim league a spokesperson for islamic association of teachers of iran ? \n",
      "\n",
      "Actual:     ask where{dbr:Islamic_Association_of_Teachers_of_Iran dbo:spokesperson dbr:Pakistan_Muslim_League_(N) }\n",
      "Processed:  ask where{dbr:Islamic_Association_of_Teachers_of_Iran dbo:spokesperson dbr:Pakistan_Muslim_League }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is indian lodge's foal day was of gunnevera ? \n",
      "\n",
      "Actual:     ask where{dbr:Gunnevera dbo:foalDate dbr:Indian_Lodge }\n",
      "Processed:  ask where{dbr:Gunnevera dbo:foalDay dbr:Indian_Lodge }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Is it likely that wom language has family ? \n",
      "\n",
      "Actual:     ask where{dbr:Wom_language_(Papua_New_Guinea) dbo:languageFamily ?x }\n",
      "Processed:  ask where{dbr:Wom_language dbo:languageFamily ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What was bill jones's birth place ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Bill_Jones_(basketball,_born_1966) dbo:birthPlace ?x1 . ?x1 dbo:originalName ?x }\n",
      "Processed:  select ?x where{dbr:Bill_Jones dbo:birthPlace ?x1. ?x1 dbo:populationDensity ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the issn of philo ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Philo_(journal) dbo:issn ?x }\n",
      "Processed:  select ?x where{dbr:Philo dbo:issn ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What are the volumes of fuichin tsaichen! and bōkyaku battery and what is their importance ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Fuichin_Tsaichen! dbo:numberOfVolumes ?x . dbr:Bōkyaku_Battery dbo:numberOfVolumes ?x }\n",
      "Processed:  select ?x where{dbr:Fuichin_Tsaichen! dbo:volume ?x. dbr:Bōkyaku_Battery dbo:volume ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Do you think mppj selangor f.c. is dissolved by utah royals fc ? \n",
      "\n",
      "Actual:     ask where{dbr:Utah_Royals_FC dbo:dissolved dbr:MPPJ_Selangor_F.C . }\n",
      "Processed:  ask where{dbr:Utah_Royals_FC dbo:dissolvedBy dbr:MPPJ_Selangor_F . C. }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the current runtime for morning on the lièvre and say a prayer ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Say_a_Prayer_(Breathe_song) dbo:runtime ?x . dbr:Morning_on_the_Lièvre dbo:runtime ?x }\n",
      "Processed:  select ?x where{dbr:Say_a_Prayer dbo:currentRuntime ?x. dbr:Morning_on_the_Lièvre dbo:currentRuntime ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # If you like beurt servaas and ruby keeler who are the spouses ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Beurt_SerVaas dbo:spouse ?x . dbr:Ruby_Keeler dbo:spouse ?x }\n",
      "Processed:  select ?x where{dbr:Ruby_Keeler dbo:spouse ?x. dbr:Beurt_Servaas dbo:spouse ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the heinz-harald frentzen as well as ricardo londoño race ? \n",
      "\n",
      "Actual:     select ?x where{dbr:Heinz-Harald_Frentzen dbo:races ?x . dbr:Ricardo_Londoño dbo:races ?x }\n",
      "Processed:  select ?x where{dbr:Ricardo_Londoño dbo:race ?x. dbr:Heinz-Harald_Frentzen dbo:race ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # When will the order of uss john finn and hms ballahoo be released ? \n",
      "\n",
      "Actual:     select ?x where{dbr:HMS_Ballahoo_(1804) dbo:orderDate ?x . dbr:USS_John_Finn dbo:orderDate ?x }\n",
      "Processed:  select ?x where{dbr:HMS_Ballahoo dbo:order ?x. dbr:USS_John_Finn dbo:order ?x }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # What is the ford cvh engine oil system of honda hr09e/hr10eg engine ? \n",
      "\n",
      "Actual:     ask where{dbr:Honda_HR09E/HR10EG_engine dbo:oilSystem dbr:Ford_CVH_engine }\n",
      "Processed:  ask where{dbr:Ford_CVH_engine dbo:oilSystem dbr:Honda_HR09E/HR10EG_engine }\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prompt:     # Was kugel product labelled with an ingredient ? \n",
      "\n",
      "Actual:     ask where{dbr:Kugel dbo:ingredientName ?x }\n",
      "Processed:  ask where{dbr:Kugel_Product dbo:ingredient ?x }\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where 'BLEU Score (Post-Processed)' is 0\n",
    "zero_score_df = df[df['BLEU Score (Post-Processed)'] == 0]\n",
    "\n",
    "# error analysis based on sample rows where BLEU Score (Post-Processed) is 0\n",
    "sampled_df = zero_score_df.sample(n=min(100, len(zero_score_df)))\n",
    "\n",
    "for index, row in sampled_df[['Prompt','Actual SPARQL', 'Post-Processed SPARQL']].iterrows():\n",
    "    print(\"Prompt:    \", row[\"Prompt\"][28:], \"\\n\")\n",
    "    print(\"Actual:    \", row[\"Actual SPARQL\"])\n",
    "    print(\"Processed: \", row[\"Post-Processed SPARQL\"])\n",
    "    print(\"-\"*100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "052b42a1-3bd2-4f4a-869b-d643f9890803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'\\nDevice: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "650a833c-5a47-4200-b174-087abf1eb5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "checkpoint=\"bigcode/starcoderbase-1b-merged\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, use_auth_token=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, use_auth_token=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2178263d-615d-4303-904f-2544269ab507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: # write a SPARQL query for:\n",
      "# What are cadolzburg area code?\n",
      "\n",
      "Answer: select?x where{dbr:Cadolzburg dbo:areaCode?x }<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"Question: # write a SPARQL query for:\\n# What are cadolzburg area code ?\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt.strip(), return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c57b141-cc13-44c1-bccf-18a563dab42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: # write a SPARQL query for:\n",
      "# How many province did avola grow in?\n",
      "\n",
      "Answer: select count(*) as?x where{dbr:Avola dbo:province?x }<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "## candidate prompt format\n",
    "\n",
    "prompt = \"Question: # write a SPARQL query for:\\n# How many province did avola grow in ?\"\n",
    "\n",
    "\n",
    "inputs = tokenizer.encode_plus(prompt.strip(), return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs['input_ids'], max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1b47c1-ba15-4676-91ae-c9a549d98cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a SPARQL query for:\n",
      "# What's the percentage of area water in bert cremean's Death place ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# Did calabritto have saint ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# How many ideologies did ganatantri dal have ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# Who is the second driver of 1976 race of champions ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# What is the ship beam of voyager of the seas as well as uss fort worth ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# How many province did avola grow in ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# What are cadolzburg area code ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# What ISO code for catalan language ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# What is the population of the city of sohawa tehsil ? \n",
      "\n",
      "# write a SPARQL query for:\n",
      "# What is the revenue of zale corporation ? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_test = pd.read_csv(\"data/nspm-fine-tuning/test.csv\")\n",
    "\n",
    "df_sample = df_test.sample(n=10, random_state=0)\n",
    "\n",
    "for i in df_sample['prompt'].to_list():\n",
    "    print(i, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c193f-8edf-4b7c-a9b8-1ae5d7ceae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "select?x where{dbr:Bert_Cremean dbo:deathPlace?x1.?x1 dbo:percentageOfAreaWater?x }<|endoftext|>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61321172-ba19-43bd-b087-40ccc4fa1b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select ?x where{dbr:Bert_Cremean dbo:deathPlace ?x1 . ?x1 dbo:percentageOfAreaWater ?x } \n",
      "\n",
      "ask where{dbr:Calabritto dbo:saint ?x } \n",
      "\n",
      "select count(*) as ?x where{dbr:Ganatantri_Dal dbo:ideology ?x } \n",
      "\n",
      "select ?x where{dbr:1976_Race_of_Champions dbo:secondDriver ?x } \n",
      "\n",
      "select ?x where{dbr:Voyager_of_the_Seas dbo:shipBeam ?x . dbr:USS_Fort_Worth dbo:shipBeam ?x } \n",
      "\n",
      "select count(*) as ?x where{dbr:Avola dbo:province ?x } \n",
      "\n",
      "select count(*) as ?x where{dbr:Cadolzburg dbo:areaCode ?x } \n",
      "\n",
      "select count(*) as ?x where{dbr:Catalan_language dbo:iso6391Code ?x } \n",
      "\n",
      "select ?x where{dbr:Sohawa_Tehsil dbo:populationRural ?x } \n",
      "\n",
      "select count(*) as ?x where{dbr:Zale_Corporation dbo:revenue ?x } \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in df_sample['completion'].to_list():\n",
    "    print(i, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
