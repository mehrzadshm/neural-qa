{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcd08e03-325a-4a3e-b020-ef68deb38b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e82a4937-c98d-474b-8b9f-71e3f88a57d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file '/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/codegen/finetune-starcoder-1b.py': [Errno 2] No such file or directory\n",
      "CPU times: user 2.73 ms, sys: 42 ms, total: 44.7 ms\n",
      "Wall time: 197 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python finetune-starcoder-1b.py\\\n",
    "--model_path=\"Salesforce/codegen-350M-multi\"\\\n",
    "--seq_length=512\\\n",
    "--batch_size=2\\\n",
    "--eos_token_id=0\\\n",
    "--save_freq=2000\\\n",
    "--seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77a70b6-a0ac-4f18-a0c8-354839d149ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T17:16:32.100885Z",
     "iopub.status.busy": "2023-08-02T17:16:32.100451Z",
     "iopub.status.idle": "2023-08-02T17:16:32.111648Z",
     "shell.execute_reply": "2023-08-02T17:16:32.111052Z",
     "shell.execute_reply.started": "2023-08-02T17:16:32.100860Z"
    },
    "tags": []
   },
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dd54397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f'\\nDevice: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5d1984-7b44-43de-af56-30c7943140aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=torch.bfloat16 with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-multi\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\", load_in_8bit=True, torch_dtype=torch.bfloat16, device_map='auto')\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"Salesforce/codegen-350M-multi\", device_map='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939db736-3d70-4f2b-807c-efc029fe8ab7",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a685075-04c1-47be-b060-8658d2dd7567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/mehr-shahin/.cache/huggingface/datasets/csv/default-3615beb83b6f428b/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b1cb4c5f1fc49c88d0ad6b0a0dd0aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['Unnamed: 0', 'prompt', 'completion'],\n",
      "        num_rows: 100000\n",
      "    })\n",
      "    val: Dataset({\n",
      "        features: ['Unnamed: 0', 'prompt', 'completion'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\n",
    "    'train': '/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/data/nspm-fine-tuning/train.csv', \n",
    "    'val': '/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/data/nspm-fine-tuning/val.csv'\n",
    "})\n",
    "\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4c9bf8b-d4fa-4a3e-a493-0bcb65598f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# write a SPARQL query for:\n",
      "# How many ICD9 did friedreich's ataxia have ?\n",
      "select count(*) as ?x where{dbr:Friedreich's_ataxia dbo:icd9 ?x }\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['prompt'])\n",
    "print(dataset['train'][0]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b38f8db-7910-4b9d-9061-53fd11ede153",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "import copy\n",
    "\n",
    "class PrepareDataset(Dataset):\n",
    "    def __init__(self, data_path=str, split='train', size=None, max_seq_length=2048):\n",
    "        self.dataset = load_dataset('csv', data_files={\n",
    "            'train': data_path + 'train.csv',\n",
    "            'val': data_path + 'val.csv',\n",
    "            'test': data_path + 'test.csv',\n",
    "        })[split]  \n",
    "        \n",
    "        if size:\n",
    "            self.dataset = self.dataset.select(range(size))\n",
    "        \n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.dataset[index]\n",
    "        prompt = torch.tensor(tokenizer.encode(item['prompt']), dtype=torch.int64)\n",
    "        example = item['prompt'] + item[\"completion\"]\n",
    "        example = tokenizer.encode(example)\n",
    "        example.append(tokenizer.eos_token_id)\n",
    "\n",
    "        if len(example) > self.max_seq_length:\n",
    "            example = example[:self.max_seq_length]\n",
    "\n",
    "        example = torch.tensor(example, dtype=torch.int64)\n",
    "        example = torch.nn.functional.pad(example, (0, self.max_seq_length - len(example)), 'constant', 0)\n",
    "        \n",
    "        labels = example.clone()\n",
    "        labels[:len(prompt)] = -100\n",
    "\n",
    "        return {\"prompt\": example, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d669cd4e-1b53-4810-aa5a-8194916b01c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/mehr-shahin/.cache/huggingface/datasets/csv/default-72c2059406228e0d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20d4e19fb0ea41d7b6e1b623e2a26b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/mehr-shahin/.cache/huggingface/datasets/csv/default-72c2059406228e0d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f70294367b746f58f1bd242453fa2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/home/mehr-shahin/.cache/huggingface/datasets/csv/default-72c2059406228e0d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aeea0e95cef4fb8bcf0d6260ebcd748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "data_path = \"/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/data/nspm-fine-tuning/\"\n",
    "\n",
    "train_dataset = PrepareDataset(data_path=data_path, split='train', size=None, max_seq_length=512)\n",
    "val_dataset = PrepareDataset(data_path=data_path, split='val', max_seq_length=512)\n",
    "test_dataset = PrepareDataset(data_path=data_path, split='test', max_seq_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d773965-a3be-40b7-9297-61978ba9f633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PrepareDataset at 0x7f81245f2190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa7f7a-1fb5-417e-bf92-e07f8c172a30",
   "metadata": {},
   "source": [
    "# Prepare PEFT for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc4f36e-907a-4320-8ea6-c750a8e7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1627483c-2739-4cc9-8d85-e7353b4c61b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehr-shahin/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target modules ['q_proj', 'v_proj'] not found in the base model. Please check the target modules and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m prepare_model_for_int8_training(model)\n\u001b[1;32m     13\u001b[0m lora_config \u001b[38;5;241m=\u001b[39m LoraConfig(\n\u001b[1;32m     14\u001b[0m     task_type\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mCAUSAL_LM,\n\u001b[1;32m     15\u001b[0m     inference_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     target_modules \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_proj\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_peft_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/mapping.py:106\u001b[0m, in \u001b[0;36mget_peft_model\u001b[0;34m(model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    105\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m _prepare_prompt_learning_config(peft_config, model_config)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/peft_model.py:889\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, peft_config: PeftConfig, adapter_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prepare_inputs_for_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation\n",
      "File \u001b[0;32m~/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/peft_model.py:111\u001b[0m, in \u001b[0;36mPeftModel.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name] \u001b[38;5;241m=\u001b[39m peft_config\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m \u001b[43mPEFT_TYPE_TO_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeft_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_additional_trainable_modules(peft_config, adapter_name)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/tuners/lora.py:274\u001b[0m, in \u001b[0;36mLoraModel.__init__\u001b[0;34m(self, model, config, adapter_name)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, config, adapter_name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:88\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minject_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Copy the peft_config in the injected model.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpeft_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\n",
      "File \u001b[0;32m~/repos/dbp/neural-qa/gsoc/mehrzad/starcoder-1b/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:222\u001b[0m, in \u001b[0;36mBaseTuner.inject_adapter\u001b[0;34m(self, model, adapter_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_and_replace(peft_config, adapter_name, target, target_name, parent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptionnal_kwargs)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_target_modules_in_base_model:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget modules \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeft_config\u001b[38;5;241m.\u001b[39mtarget_modules\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the base model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the target modules and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_only_adapters_as_trainable()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name]\u001b[38;5;241m.\u001b[39minference_mode:\n",
      "\u001b[0;31mValueError\u001b[0m: Target modules ['q_proj', 'v_proj'] not found in the base model. Please check the target modules and try again."
     ]
    }
   ],
   "source": [
    "from peft import (\n",
    "    get_peft_model,\n",
    "    LoraConfig,\n",
    "    TaskType,\n",
    "    prepare_model_for_int8_training,\n",
    ")\n",
    "\n",
    "\n",
    "model.train()\n",
    "\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules = [\"q_proj\", \"v_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8b18d-a25a-4d12-ac00-0f720703f579",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-02T17:50:38.809539Z",
     "iopub.status.busy": "2023-08-02T17:50:38.809187Z",
     "iopub.status.idle": "2023-08-02T17:50:38.836443Z",
     "shell.execute_reply": "2023-08-02T17:50:38.835678Z",
     "shell.execute_reply.started": "2023-08-02T17:50:38.809520Z"
    },
    "tags": []
   },
   "source": [
    "# Finetune the model with Huggingface trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997db2e9-9b2e-4169-9b18-695d403f70e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import default_data_collator, Trainer, TrainingArguments\n",
    "\n",
    "output_dir = \"training_run\"\n",
    "\n",
    "config = {\n",
    "    'lora_config': lora_config,\n",
    "    'learning_rate': 1e-4,\n",
    "    'num_train_epochs': 1,\n",
    "    'gradient_accumulation_steps': 2,\n",
    "    'gradient_checkpointing': False,\n",
    "}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    bf16=True,\n",
    "    # logging strategies\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=5,\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    **{k:v for k,v in config.items() if k != 'lora_config'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007525f0-41ac-4de7-aba8-92e547931972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=default_data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680eb420-2c91-407c-b19c-89ea0391b591",
   "metadata": {},
   "source": [
    "# Save model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1fb82e-b158-40d7-92bf-d63446dc12ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaeb1d5-1b49-4873-a205-b3ba94af4214",
   "metadata": {},
   "source": [
    "# Evaluate the finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e98d82-07de-48fa-8c40-fb59e7805b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad30645-9472-4d29-94f8-94e20fdde79a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = \"\"\"CREATE TABLE stadium (\n",
    "    stadium_id number,\n",
    "    location text,\n",
    "    name text,\n",
    "    capacity number,\n",
    ")\n",
    "\n",
    "-- Using valid SQLite, answer the following questions for the tables provided above.\n",
    "\n",
    "-- how many stadiums in total?\n",
    "\n",
    "SELECT\"\"\"\n",
    "\n",
    "model_input = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "generated_ids = model.generate(**model_input, max_new_tokens=100)\n",
    "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532632db-3579-48dd-931b-b6aa4669ce87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
